{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1bf3baa9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-25T22:11:51.957387Z",
          "iopub.status.busy": "2023-10-25T22:11:51.956945Z",
          "iopub.status.idle": "2023-10-25T22:11:51.965701Z",
          "shell.execute_reply": "2023-10-25T22:11:51.964581Z",
          "shell.execute_reply.started": "2023-10-25T22:11:51.957351Z"
        },
        "papermill": {
          "duration": 0.01381,
          "end_time": "2024-02-21T15:53:29.633895",
          "exception": false,
          "start_time": "2024-02-21T15:53:29.620085",
          "status": "completed"
        },
        "tags": [],
        "id": "1bf3baa9"
      },
      "source": [
        "# Using Vector/Embedding DB to provide context to an LLM\n",
        "\n",
        "<!-- HOW TO USE A VECTOR / EMBEDDING DATABASE TO PROVIDE CONTEXT TO A LARGE LANGUAGE MODEL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa5d617a",
      "metadata": {
        "papermill": {
          "duration": 0.014165,
          "end_time": "2024-02-21T15:53:29.661089",
          "exception": false,
          "start_time": "2024-02-21T15:53:29.646924",
          "status": "completed"
        },
        "tags": [],
        "id": "fa5d617a"
      },
      "source": [
        "In this notebook we will see how to use an embedding database to store the information that we want to pass to a large language model so that it takes it into account in its responses.\n",
        "\n",
        "The information could be our own documents, or whatever was contained in a business knowledge database.\n",
        "\n",
        "I have prepared the notebook so that it can work with three different Kaggle datasets, so that it is easy to carry out different tests with different Datasets.\n",
        "\n",
        "![VectorDatabase.png](attachment:a73106c8-f286-41fc-b9d7-66638412114c.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09610bd9",
      "metadata": {
        "papermill": {
          "duration": 0.013223,
          "end_time": "2024-02-21T15:53:29.688221",
          "exception": false,
          "start_time": "2024-02-21T15:53:29.674998",
          "status": "completed"
        },
        "tags": [],
        "id": "09610bd9"
      },
      "source": [
        "## Import and load the libraries\n",
        "\n",
        "To start we need to install the necesary Python packages.\n",
        "* **[sentence transformers](http:/www.sbert.net/)**. This library is necessary to transform the sentences into fixed-length vectors, also know as embeddings.\n",
        "* **[xformers](https://github.com/facebookresearch/xformers)**. it's a package that provides libraries an utilities to facilitate the work with transformers models. We need to install in order to avoid an error when we work with the model and embeddings.  \n",
        "* **[chromadb](https://www.trychroma.com/)**. This is our vector Database. ChromaDB is easy to use and open source, maybe the most used Vector Database used to store embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c76ddb52",
      "metadata": {
        "papermill": {
          "duration": 255.882104,
          "end_time": "2024-02-21T15:58:19.938786",
          "exception": false,
          "start_time": "2024-02-21T15:54:04.056682",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c76ddb52",
        "outputId": "55249d94-9c1e-4a3e-d668-0bc93d2c2cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.1.1 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.7/507.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        " !pip install -q sentence-transformers==2.2.2\n",
        " !pip install -q xformers==0.0.23\n",
        " !pip install -q chromadb==0.4.20"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KcBDXt7ejlB-",
        "outputId": "b806ed59-a78b-4bb3-9435-cead03e8c09f"
      },
      "id": "KcBDXt7ejlB-",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.1.1)\n",
            "Collecting torch\n",
            "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch)\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
            "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.18.1\n",
            "    Uninstalling nvidia-nccl-cu12-2.18.1:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
            "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.1\n",
            "    Uninstalling torch-2.1.1:\n",
            "      Successfully uninstalled torch-2.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.23 requires torch==2.1.1, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 torch-2.5.1 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45f00ad4",
      "metadata": {
        "papermill": {
          "duration": 0.01578,
          "end_time": "2024-02-21T15:58:19.972462",
          "exception": false,
          "start_time": "2024-02-21T15:58:19.956682",
          "status": "completed"
        },
        "tags": [],
        "id": "45f00ad4"
      },
      "source": [
        "I'm sure that you know the next two packages: Numpy and Pandas, maybe the most used python libraries.\n",
        "\n",
        "Numpy is a powerful library for numerical computing.\n",
        "\n",
        "Pandas is a library for data manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "39ce0d3f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T15:58:20.008Z",
          "iopub.status.busy": "2024-02-21T15:58:20.006829Z",
          "iopub.status.idle": "2024-02-21T15:58:20.013724Z",
          "shell.execute_reply": "2024-02-21T15:58:20.01249Z"
        },
        "papermill": {
          "duration": 0.028165,
          "end_time": "2024-02-21T15:58:20.016814",
          "exception": false,
          "start_time": "2024-02-21T15:58:19.988649",
          "status": "completed"
        },
        "tags": [],
        "id": "39ce0d3f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57dad70f",
      "metadata": {
        "papermill": {
          "duration": 0.016026,
          "end_time": "2024-02-21T15:58:20.049214",
          "exception": false,
          "start_time": "2024-02-21T15:58:20.033188",
          "status": "completed"
        },
        "tags": [],
        "id": "57dad70f"
      },
      "source": [
        "## Load the Dataset\n",
        "\n",
        "As you can see the notebook is ready to work with three different Datasets. Just uncomment the lines of the Dataset you want to use.\n",
        "\n",
        "I selected Datasets with News. Two of them have just a brief decription of the new, but the other contains the full text.\n",
        "\n",
        "As we are working in a free and limited space, and we can use just 30 gb of memory I limited the number of news to use with the variable MAX_NEWS.\n",
        "\n",
        "The name of the field containing the text of the new is stored in the variable *DOCUMENT* and the metadata in *TOPIC*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e70a47e0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T15:58:20.084447Z",
          "iopub.status.busy": "2024-02-21T15:58:20.083438Z",
          "iopub.status.idle": "2024-02-21T15:58:21.232033Z",
          "shell.execute_reply": "2024-02-21T15:58:21.230551Z"
        },
        "papermill": {
          "duration": 1.170763,
          "end_time": "2024-02-21T15:58:21.235862",
          "exception": false,
          "start_time": "2024-02-21T15:58:20.065099",
          "status": "completed"
        },
        "tags": [],
        "id": "e70a47e0"
      },
      "outputs": [],
      "source": [
        "news = pd.read_csv('articles.csv')\n",
        "MAX_NEWS = 100\n",
        "DOCUMENT=\"Article Body\"\n",
        "TOPIC=\"Article Header\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeb276f4",
      "metadata": {
        "papermill": {
          "duration": 0.016461,
          "end_time": "2024-02-21T15:58:21.268282",
          "exception": false,
          "start_time": "2024-02-21T15:58:21.251821",
          "status": "completed"
        },
        "tags": [],
        "id": "aeb276f4"
      },
      "source": [
        "ChromaDB requires that the data has a unique identifier. We can make it with this statement, which will create a new column called **Id**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "61c151df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T15:58:21.303759Z",
          "iopub.status.busy": "2024-02-21T15:58:21.302999Z",
          "iopub.status.idle": "2024-02-21T15:58:21.336701Z",
          "shell.execute_reply": "2024-02-21T15:58:21.335126Z"
        },
        "papermill": {
          "duration": 0.054847,
          "end_time": "2024-02-21T15:58:21.339906",
          "exception": false,
          "start_time": "2024-02-21T15:58:21.285059",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "61c151df",
        "outputId": "e4198857-88c7-4171-f663-2560d0190e27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 Published Date                Author  \\\n",
              "0           0   July 7, 2023             Adam Zewe   \n",
              "1           1   July 6, 2023           Alex Ouyang   \n",
              "2           2  June 30, 2023  Jennifer Michalowski   \n",
              "3           3  June 30, 2023   Mary Beth Gallagher   \n",
              "4           4  June 30, 2023             Adam Zewe   \n",
              "\n",
              "                                              Source  \\\n",
              "0                                    MIT News Office   \n",
              "1  Abdul Latif Jameel Clinic for Machine Learning...   \n",
              "2              McGovern Institute for Brain Research   \n",
              "3                              School of Engineering   \n",
              "4                                    MIT News Office   \n",
              "\n",
              "                                      Article Header  \\\n",
              "0  Learning the language of molecules to predict ...   \n",
              "1  MIT scientists build a system that can generat...   \n",
              "2  When computer vision works more like a brain, ...   \n",
              "3  Educating national security leaders on artific...   \n",
              "4  Researchers teach an AI to write better chart ...   \n",
              "\n",
              "                                        Sub_Headings  \\\n",
              "0  This AI system only needs a small amount of da...   \n",
              "1  BioAutoMATED, an open-source, automated machin...   \n",
              "2  Training artificial neural networks with data ...   \n",
              "3  Experts from MIT’s School of Engineering, Schw...   \n",
              "4  A new dataset can help scientists develop auto...   \n",
              "\n",
              "                                        Article Body  \\\n",
              "0  ['Discovering new materials and drugs typicall...   \n",
              "1  ['Is it possible to build machine-learning mod...   \n",
              "2  ['From cameras to self-driving cars, many of t...   \n",
              "3  ['Understanding artificial intelligence and ho...   \n",
              "4  ['Chart captions that explain complex trends a...   \n",
              "\n",
              "                                                 Url  id  \n",
              "0  https://news.mit.edu/2023/learning-language-mo...   0  \n",
              "1  https://news.mit.edu/2023/bioautomated-open-so...   1  \n",
              "2  https://news.mit.edu/2023/when-computer-vision...   2  \n",
              "3  https://news.mit.edu/2023/educating-national-s...   3  \n",
              "4  https://news.mit.edu/2023/researchers-chart-ca...   4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6caa0de8-ed16-4c8a-8d06-080c70ea8747\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Published Date</th>\n",
              "      <th>Author</th>\n",
              "      <th>Source</th>\n",
              "      <th>Article Header</th>\n",
              "      <th>Sub_Headings</th>\n",
              "      <th>Article Body</th>\n",
              "      <th>Url</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>July 7, 2023</td>\n",
              "      <td>Adam Zewe</td>\n",
              "      <td>MIT News Office</td>\n",
              "      <td>Learning the language of molecules to predict ...</td>\n",
              "      <td>This AI system only needs a small amount of da...</td>\n",
              "      <td>['Discovering new materials and drugs typicall...</td>\n",
              "      <td>https://news.mit.edu/2023/learning-language-mo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>July 6, 2023</td>\n",
              "      <td>Alex Ouyang</td>\n",
              "      <td>Abdul Latif Jameel Clinic for Machine Learning...</td>\n",
              "      <td>MIT scientists build a system that can generat...</td>\n",
              "      <td>BioAutoMATED, an open-source, automated machin...</td>\n",
              "      <td>['Is it possible to build machine-learning mod...</td>\n",
              "      <td>https://news.mit.edu/2023/bioautomated-open-so...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>June 30, 2023</td>\n",
              "      <td>Jennifer Michalowski</td>\n",
              "      <td>McGovern Institute for Brain Research</td>\n",
              "      <td>When computer vision works more like a brain, ...</td>\n",
              "      <td>Training artificial neural networks with data ...</td>\n",
              "      <td>['From cameras to self-driving cars, many of t...</td>\n",
              "      <td>https://news.mit.edu/2023/when-computer-vision...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>June 30, 2023</td>\n",
              "      <td>Mary Beth Gallagher</td>\n",
              "      <td>School of Engineering</td>\n",
              "      <td>Educating national security leaders on artific...</td>\n",
              "      <td>Experts from MIT’s School of Engineering, Schw...</td>\n",
              "      <td>['Understanding artificial intelligence and ho...</td>\n",
              "      <td>https://news.mit.edu/2023/educating-national-s...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>June 30, 2023</td>\n",
              "      <td>Adam Zewe</td>\n",
              "      <td>MIT News Office</td>\n",
              "      <td>Researchers teach an AI to write better chart ...</td>\n",
              "      <td>A new dataset can help scientists develop auto...</td>\n",
              "      <td>['Chart captions that explain complex trends a...</td>\n",
              "      <td>https://news.mit.edu/2023/researchers-chart-ca...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6caa0de8-ed16-4c8a-8d06-080c70ea8747')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6caa0de8-ed16-4c8a-8d06-080c70ea8747 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6caa0de8-ed16-4c8a-8d06-080c70ea8747');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ccf51f98-0f33-4c28-86a8-07486550aa8f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ccf51f98-0f33-4c28-86a8-07486550aa8f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ccf51f98-0f33-4c28-86a8-07486550aa8f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "news",
              "summary": "{\n  \"name\": \"news\",\n  \"rows\": 1018,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 294,\n        \"min\": 0,\n        \"max\": 1017,\n        \"num_unique_values\": 1018,\n        \"samples\": [\n          528,\n          914,\n          587\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Published Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 845,\n        \"samples\": [\n          \"September 7, 2018\",\n          \"July 21, 2021\",\n          \"June 13, 2016\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 147,\n        \"samples\": [\n          \"David Chandler, MIT News Office\",\n          \"Michaela Jarvis\",\n          \"Andrew Spann, Class of 2007\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 80,\n        \"samples\": [\n          \"School of Humanities, Arts, and Social Sciences\",\n          \"MIT News Office\",\n          \"Department of Chemical Engineering\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Article Header\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1018,\n        \"samples\": [\n          \"Teaching artificial intelligence to connect senses like vision and touch\",\n          \"A robot high for Archimedes Pi\",\n          \"MIMIC Chest X-Ray database to provide researchers access to over 350,000 patient radiographs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_Headings\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 869,\n        \"samples\": [\n          \"MIT professor announced as award\\u2019s first recipient for work in cancer diagnosis and drug synthesis.\",\n          \"The chatbot\\u2019s success on the medical licensing exam shows that the test \\u2014 and medical education \\u2014 are flawed, Celi says.\",\n          \"Move over, Alexa and Siri. Talking Mabu robot provides one-to-one support while relaying information to doctors.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Article Body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 987,\n        \"samples\": [\n          \"['\\u201cThe challenge for humanity now is how to decarbonize the global economy by 2050. To do that, we need a supercharged decade of energy innovation,\\u201d said Ernest J. Moniz, the Cecil and Ida Green Professor of Physics and Engineering Systems Emeritus, founding director of the MIT Energy Initiative, and a former U.S. secretary of energy, as he opened the MIT Forefront virtual event on April 21. \\u201cBut we also need practical visionaries, in every economic sector, to develop new business models that allow them to remain profitable while achieving the zero-carbon emissions.\\u201d', 'The event, \\u201cAddressing Climate and Sustainability through Technology, Policy, and Business Models,\\u201d was the third in the MIT Forefront series, which invites top minds from the worlds of science, industry, and policy to propose bold new answers to urgent global problems. Moniz moderated the event, and more than 12,000 people tuned in online.', 'MIT and other universities play an important role in preparing the world\\u2019s best minds to take on big climate challenges and develop the technology needed to advance sustainability efforts, a point illustrated in the main session with a video about Via Separations, a company supported by MIT\\u2019s The Engine. Co-founded by Shreya Dave \\u201909, SM \\u201912, PhD \\u201916, Via Separations customizes filtration technology to reduce waste and save money across multiple industries. \\u201cBy next year, we are going to be eliminating carbon dioxide emissions from our customers\\u2019 facilities,\\u201d Dave said.', 'Via Separations is one of many innovative companies born of MIT\\u2019s energy and climate initiatives \\u2014 the work of which, as the panel went on to discuss, is critical to achieving net-zero emissions and deploying successful environmental sustainability efforts. As Moniz put it, the company embodies \\u201cthe spirit of science and technology in action for the good of humankind\\u201d and exemplifies how universities and businesses, as well as technology and policy, must work together to make the best environmental choices.', 'How businesses confront climate change', 'Innovation in sustainable practices can be met with substantial challenges when proposed or applied to business models, particularly on the policy side, the panelists noted. But they shared some key ways that their respective organizations have employed current technologies and the challenges they face in reaching their sustainability goals. Despite each business\\u2019s different products and services, a common thread of needing new technologies to achieve their sustainability goals emerged.', 'Although 2050 is the long-term goal for net-zero emissions put forth by the Paris Agreement, the businesses represented by the panelists are thinking about the shorter term. \\u201cIBM has committed to net-zero emissions by 2030 \\u2015 without carbon offsets,\\u201d said Arvind Krishna, chairman and chief executive officer of IBM. \\u201cWe believe that some carbon taxes would be a good policy tool. But policy alone is insufficient. We need advanced technological tools to reach our goal.\\u201d', 'Jeff Wilke SM \\u201993, who retired as Amazon\\u2019s chief executive officer of Worldwide Consumer in February 2021, outlined a number of initiatives that the online retail giant is undertaking to curb emissions. Transportation is one of their biggest hurdles to reaching zero emissions, leading to a significant investment in Class 8 electric trucks. \\u201cAnother objective is to remove the need for plane shipments by getting inventory closer to urban areas, and that has been happening steadily over the years,\\u201d he said.', 'Jim Fitterling, chair and chief executive officer of Dow, explained that Dow has reduced its carbon emissions by 15 percent in the past decade and is poised to reduce it further in the next. Future goals include working toward electrifying ethylene production. \\u201cIf we can electrify that, it will allow us to make major strides toward carbon-dioxide reduction,\\u201d he said. \\u201cBut we need more reliable and stable power to get to that point.\\u201d', 'Collaboration is key to advancing climate solutions', \\\"Maria T. Zuber, MIT\\u2019s vice president for research, who was recently appointed by U.S. President Joe Biden as co-chair of the President's Council of Advisors on Science and Technology, stressed that MIT innovators and industry leaders must work together to implement climate solutions.\\\", '\\u201cInnovation is a team sport,\\u201d said Zuber, who is also the E. A. Griswold Professor of Geophysics. \\u201cEven if MIT researchers make a huge discovery, deploying it requires cooperation on a policy level and often industry support. Policymakers need to solve problems and seize opportunities in ways that are popular. It\\u2019s not just solving technical problems \\u2015 there is a human behavior component.\\u201d', 'But businesses, Zuber said, can play a huge role in advancing innovation. \\u201cIf a company becomes convinced of the potential of a new technology, they can be the best advocates with policymakers,\\u201d she said.', 'The question of \\u201csustainability vs. shareholders\\u201d', 'During the Q&A session, an audience member pointed out that environmentalists are often distrustful of companies\\u2019 sustainability policies when their focus is on shareholders and profit.', '\\u201cCompanies have to show that they\\u2019re part of the solution,\\u201d Fitterling said. \\u201cInvestors will be afraid of high costs up front, so, say, completely electrifying a plant overnight is off the table. You have to make a plan to get there, and then incentivize that plan through policy. Carbon taxes are one way, but miss the market leverage.\\u201d', 'Krishna also pushed back on the idea that companies have to choose between sustainability and profit. \\u201cIt\\u2019s a false dichotomy,\\u201d he said. \\u201cIf companies were only interested in short-term profits, they wouldn\\u2019t last for long.\\u201d', '\\u201cA belief I\\u2019ve heard from some environmental groups is that \\u2018anything a company does is greenwashing,\\u2019 and that they\\u2019ll abandon those efforts if the economy tanks,\\u201d Zuber said, referring to a practice wherein organizations spend more time marketing themselves as environmentally sustainable than on maximizing their sustainability efforts. \\u201cThe economy tanked in 2020, though, and we saw companies double down on their sustainability plans. They see that it\\u2019s good for business.\\u201d', 'The role of universities and businesses in sustainability innovation', '\\u201cAmazon and all corporations are adapting to the effects of climate change, like extreme weather patterns, and will need to adapt more \\u2014 but I\\u2019m not ready to throw in the towel for decarbonization,\\u201d Wilke said. \\u201cEither way, companies will have to invest in decarbonization. There is no way we are going to make the progress we have to make without it.\\u201d', 'Another component is the implications of artificial intelligence (AI) and quantum computing. Krishna noted multiple ways that AI and quantum computing will play a role at IBM, including finding the most environmentally sustainable and cost-efficient ways to advance carbon separation in exhaust gases and lithium battery life in electric cars.', 'AI, quantum computing, and alternate energy sources such as fusion energy that have the potential to achieve net-zero energy, are key areas that students, researchers, and faculty members are pursuing at MIT.', '\\u201cUniversities like MIT need to go as fast as we can as far as we can with the science and technology we have now,\\u201d Zuber said. \\u201cIn parallel, we need to invest in and deploy a suite of new tools in science and technology breakthroughs that we need to reach the 2050 goal of decarbonizing. Finally, we need to continue to train the next generation of students and researchers who are solving these issues and deploy them to these companies to figure it out.\\u201d']\",\n          \"['The inner child in many of us feels an overwhelming sense of joy when stumbling across a pile of the fluorescent, rubbery mixture of water, salt, and flour that put goo on the map: play dough. (Even if this happens rarely in adulthood.)', 'While manipulating play dough is fun and easy for 2-year-olds, the shapeless sludge is hard for robots to handle. Machines have become increasingly reliable with rigid objects, but manipulating soft, deformable objects comes with a laundry list of technical challenges, and most importantly, as with most flexible structures, if you move one part, you\\u2019re likely affecting everything else.', 'Scientists from MIT\\u2019s Computer Science and Artificial Intelligence Laboratory (CSAIL) and Stanford University recently let robots take their hand at playing with the modeling compound, but not for nostalgia\\u2019s sake. Their new system learns directly from visual inputs to let a robot with a two-fingered gripper see, simulate, and shape doughy objects. \\u201cRoboCraft\\u201d could reliably plan a robot\\u2019s behavior to pinch and release play dough to make various letters, including ones it had never seen. With just 10 minutes of data, the two-finger gripper rivaled human counterparts that teleoperated the machine \\u2014 performing on-par, and at times even better, on the tested tasks.', '\\u201cModeling and manipulating objects with high degrees of freedom are essential capabilities for robots to learn how to enable complex industrial and household interaction tasks, like stuffing dumplings, rolling sushi, and making pottery,\\u201d says Yunzhu Li, CSAIL PhD student and author on a new paper about RoboCraft. \\u201cWhile there\\u2019s been recent advances in manipulating clothes and ropes, we found that objects with high plasticity, like dough or plasticine \\u2014 despite ubiquity in those household and industrial settings \\u2014 was a largely underexplored territory. With RoboCraft, we learn the dynamics models directly from high-dimensional sensory data, which offers a promising data-driven avenue for us to perform effective planning.\\u201d']\",\n          \"['MIT.nano has announced the first recipients of NCSOFT seed grants to foster hardware and software innovations in gaming technology. The grants are part of the new MIT.nano Immersion Lab Gaming program, with inaugural funding provided by video game developer NCSOFT, a founding member of the MIT.nano Consortium.', 'The newly awarded projects address topics such as 3-D/4-D data interaction and analysis, behavioral learning, fabrication of sensors, light field manipulation, and micro-display optics.', '\\u201cNew technologies and new paradigms of gaming will change the way researchers conduct their work by enabling immersive visualization and multi-dimensional interaction,\\u201d says MIT.nano Associate Director Brian W. Anthony. \\u201cThis year\\u2019s funded projects highlight the wide range of topics that will be enhanced and influenced by augmented and virtual reality.\\u201d', 'In addition to the sponsored research funds, each awardee will be given funds specifically to foster a community of collaborative users of MIT.nano\\u2019s Immersion Lab.', 'The MIT.nano Immersion Lab is a new, two-story immersive space dedicated to visualization, augmented and virtual reality (AR/VR), and the depiction and analysis of spatially related data. Currently being outfitted with equipment and software tools, the facility will be available starting this semester for use by researchers and educators interested in using and creating new experiences, including the seed grant projects.', 'The five projects to receive NCSOFT seed grants are:', 'Stefanie Mueller: connecting the virtual and physical world', 'Virtual game play is often accompanied by a prop \\u2014 a steering wheel, a tennis racket, or some other object the gamer uses in the physical world to create a reaction in the virtual game. Build-it-yourself cardboard kits have expanded access to these props by lowering costs; however, these kits are pre-cut, and thus limited in form and function. What if users could build their own dynamic props that evolve as they progress through the game?', 'Department of Electrical Engineering and Computer Science (EECS) Professor Stefanie Mueller aims to enhance the user\\u2019s experience by developing a new type of gameplay with tighter virtual-physical connection. In Mueller\\u2019s game, the player unlocks a physical template after completing a virtual challenge, builds a prop from this template, and then, as the game progresses, can unlock new functionalities to that same item. The prop can be expanded upon and take on new meaning, and the user learns new technical skills by building physical prototypes.', 'Luca Daniel and Micha Feigin-Almon: replicating human movements in virtual characters', 'Athletes, martial artists, and ballerinas share the ability to move their body in an elegant manner that efficiently converts energy and minimizes injury risk. Professor Luca Daniel, EECS and Research Laboratory of Electronics, and Micha Feigin-Almon, research scientist in mechanical engineering, seek to compare the movements of trained and untrained individuals to learn the limits of the human body with the goal of generating elegant, realistic movement trajectories for virtual reality characters.', 'In addition to use in gaming software, their research on different movement patterns will predict stresses on joints, which could lead to nervous system models for use by artists and athletes.', 'Wojciech Matusik: using phase-only holograms', 'Holographic displays are optimal for use in augmented and virtual reality. However, critical issues show a need for improvement. Out-of-focus objects look unnatural, and complex holograms have to be converted to phase-only or amplitude-only in order to be physically realized. To combat these issues, EECS Professor Wojciech Matusik proposes to adopt machine learning techniques for synthesis of phase-only holograms in an end-to-end fashion. Using a learning-based approach, the holograms could display visually appealing three-dimensional objects.', '\\u201cWhile this system is specifically designed for varifocal, multifocal, and light field displays, we firmly believe that extending it to work with holographic displays has the greatest potential to revolutionize the future of near-eye displays and provide the best experiences for gaming,\\u201d says Matusik.', 'Fox Harrell: teaching socially impactful behavior', 'Project VISIBLE \\u2014 Virtuality for Immersive Socially Impactful Behavioral Learning Enhancement \\u2014 utilizes virtual reality in an educational setting to teach users how to recognize, cope with, and avoid committing microaggressions. In a virtual environment designed by Comparative Media Studies Professor Fox Harrell, users will encounter micro-insults, followed by major micro-aggression themes. The user\\u2019s physical response drives the narrative of the scenario, so one person can play the game multiple times and reach different conclusions, thus learning the various implications of social behavior.', 'Juejun Hu: displaying a wider field of view in high resolution', 'Professor Juejun Hu from the Department of Materials Science and Engineering seeks to develop high-performance, ultra-thin immersive micro-displays for AR/VR applications. These displays, based on metasurface optics, will allow for a large, continuous field of view, on-demand control of optical wavefronts, high-resolution projection, and a compact, flat, lightweight engine. While current commercial waveguide AR/VR systems offer less than 45 degrees of visibility, Hu and his team aim to design a high-quality display with a field of view close to 180 degrees.']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1018,\n        \"samples\": [\n          \"https://news.mit.edu/2019/teaching-ai-to-connect-senses-vision-touch-0617\",\n          \"https://news.mit.edu/2005/iap-maslab\",\n          \"https://news.mit.edu/2019/mimic-chest-x-ray-database-0201\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 294,\n        \"min\": 0,\n        \"max\": 1017,\n        \"num_unique_values\": 1018,\n        \"samples\": [\n          528,\n          914,\n          587\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "news[\"id\"] = news.index\n",
        "news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "1849922b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T15:58:21.375816Z",
          "iopub.status.busy": "2024-02-21T15:58:21.375346Z",
          "iopub.status.idle": "2024-02-21T15:58:21.381048Z",
          "shell.execute_reply": "2024-02-21T15:58:21.379759Z"
        },
        "papermill": {
          "duration": 0.027701,
          "end_time": "2024-02-21T15:58:21.383814",
          "exception": false,
          "start_time": "2024-02-21T15:58:21.356113",
          "status": "completed"
        },
        "tags": [],
        "id": "1849922b"
      },
      "outputs": [],
      "source": [
        "#Because it is just a course we select a small portion of News.\n",
        "subset_news = news.head(MAX_NEWS)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "893babc1",
      "metadata": {
        "papermill": {
          "duration": 0.015939,
          "end_time": "2024-02-21T15:58:21.416088",
          "exception": false,
          "start_time": "2024-02-21T15:58:21.400149",
          "status": "completed"
        },
        "tags": [],
        "id": "893babc1"
      },
      "source": [
        "## Import and configure the Vector Database\n",
        "\n",
        "I'm going to use ChromaDB, the most popular OpenSource embedding Database.\n",
        "\n",
        "First we need to import ChromaDB, and after that import the **Settings** class from **chromadb.config** module. This class allows us to change the setting for the ChromaDB system, and customize its behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "82db86aa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T15:58:21.451092Z",
          "iopub.status.busy": "2024-02-21T15:58:21.450617Z",
          "iopub.status.idle": "2024-02-21T15:58:22.524885Z",
          "shell.execute_reply": "2024-02-21T15:58:22.523367Z"
        },
        "papermill": {
          "duration": 1.095805,
          "end_time": "2024-02-21T15:58:22.528102",
          "exception": false,
          "start_time": "2024-02-21T15:58:21.432297",
          "status": "completed"
        },
        "tags": [],
        "id": "82db86aa"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from chromadb.config import Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "051bc3a1",
      "metadata": {
        "papermill": {
          "duration": 0.015938,
          "end_time": "2024-02-21T15:58:22.560953",
          "exception": false,
          "start_time": "2024-02-21T15:58:22.545015",
          "status": "completed"
        },
        "tags": [],
        "id": "051bc3a1"
      },
      "source": [
        "Now we need to create the seetings object calling the **Settings** function imported previously. We store the object in the variable **settings_chroma**.\n",
        "\n",
        "Is necessary to inform two parameters\n",
        "* chroma_db_impl. Here we specify the database implementation and the format how store the data. I choose ***duckdb***, because his high-performace. It operate primarly in memory. And is fully compatible with SQL. The store format ***parquet*** is good for tabular data. With good compression rates and performance.\n",
        "\n",
        "* persist_directory: It just contains the directory where the data will be stored. Is possible work without a directory and the data will be stored in memory without persistece, but Kaggle dosn't support that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "b21a77ff",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T15:58:22.595859Z",
          "iopub.status.busy": "2024-02-21T15:58:22.595386Z",
          "iopub.status.idle": "2024-02-21T15:58:23.214597Z",
          "shell.execute_reply": "2024-02-21T15:58:23.213149Z"
        },
        "papermill": {
          "duration": 0.640745,
          "end_time": "2024-02-21T15:58:23.217828",
          "exception": false,
          "start_time": "2024-02-21T15:58:22.577083",
          "status": "completed"
        },
        "tags": [],
        "id": "b21a77ff"
      },
      "outputs": [],
      "source": [
        "#OLD VERSION\n",
        "#settings_chroma = Settings(chroma_db_impl=\"duckdb+parquet\",\n",
        "#                          persist_directory='./input')\n",
        "#chroma_client = chromadb.Client(settings_chroma)\n",
        "\n",
        "#NEW VERSION => 0.40\n",
        "chroma_client = chromadb.PersistentClient(path=\"/path/to/persist/directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5176774",
      "metadata": {
        "papermill": {
          "duration": 0.016853,
          "end_time": "2024-02-21T15:58:23.252446",
          "exception": false,
          "start_time": "2024-02-21T15:58:23.235593",
          "status": "completed"
        },
        "tags": [],
        "id": "b5176774"
      },
      "source": [
        "## Filling and Querying the ChromaDB Database\n",
        "\n",
        "The Data in ChromaDB is stored in collections. If the collection exist we need to delete it.\n",
        "\n",
        "In the next lines, we are creating the collection by calling the ***create_collection*** function in the ***chroma_client*** created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "a0cc5748",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T15:58:23.287232Z",
          "iopub.status.busy": "2024-02-21T15:58:23.286773Z",
          "iopub.status.idle": "2024-02-21T15:58:23.354807Z",
          "shell.execute_reply": "2024-02-21T15:58:23.353364Z"
        },
        "papermill": {
          "duration": 0.090234,
          "end_time": "2024-02-21T15:58:23.358887",
          "exception": false,
          "start_time": "2024-02-21T15:58:23.268653",
          "status": "completed"
        },
        "tags": [],
        "id": "a0cc5748"
      },
      "outputs": [],
      "source": [
        "collection_name = \"news_collection\"\n",
        "if len(chroma_client.list_collections()) > 0 and collection_name in [chroma_client.list_collections()[0].name]:\n",
        "        chroma_client.delete_collection(name=collection_name)\n",
        "\n",
        "collection = chroma_client.create_collection(name=collection_name)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "688831d1",
      "metadata": {
        "papermill": {
          "duration": 0.01831,
          "end_time": "2024-02-21T15:58:23.394771",
          "exception": false,
          "start_time": "2024-02-21T15:58:23.376461",
          "status": "completed"
        },
        "tags": [],
        "id": "688831d1"
      },
      "source": [
        "It's time to add the data to the collection. Using the function ***add*** we need to inform, at least ***documents***, ***metadatas*** and ***ids***.\n",
        "* In the **document** we store the big text, it's a different column in each Dataset.\n",
        "* In **metadatas**, we can informa a list of topics.\n",
        "* In **id** we need to inform an unique identificator for each row. It MUST be unique! I'm creating the ID using the range of MAX_NEWS.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "4fb1a28a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T15:58:23.430026Z",
          "iopub.status.busy": "2024-02-21T15:58:23.429052Z",
          "iopub.status.idle": "2024-02-21T15:59:53.084962Z",
          "shell.execute_reply": "2024-02-21T15:59:53.082483Z"
        },
        "papermill": {
          "duration": 89.680388,
          "end_time": "2024-02-21T15:59:53.091437",
          "exception": false,
          "start_time": "2024-02-21T15:58:23.411049",
          "status": "completed"
        },
        "tags": [],
        "id": "4fb1a28a"
      },
      "outputs": [],
      "source": [
        "\n",
        "collection.add(\n",
        "    documents=subset_news[DOCUMENT].tolist(),\n",
        "    metadatas=[{TOPIC: topic} for topic in subset_news[TOPIC].tolist()],\n",
        "    ids=[f\"id{x}\" for x in range(MAX_NEWS)],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "ff6a4fcf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T15:59:53.137694Z",
          "iopub.status.busy": "2024-02-21T15:59:53.137076Z",
          "iopub.status.idle": "2024-02-21T15:59:53.231901Z",
          "shell.execute_reply": "2024-02-21T15:59:53.230473Z"
        },
        "papermill": {
          "duration": 0.121938,
          "end_time": "2024-02-21T15:59:53.236515",
          "exception": false,
          "start_time": "2024-02-21T15:59:53.114577",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff6a4fcf",
        "outputId": "ab34fab4-c56f-4f4c-d908-5e470734d161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [['id90', 'id61', 'id56', 'id11', 'id16', 'id45', 'id92', 'id48', 'id46', 'id81']], 'distances': [[0.9863173961639404, 1.3655539751052856, 1.37240731716156, 1.4141846895217896, 1.4157240390777588, 1.4297924041748047, 1.442529559135437, 1.4432754516601562, 1.4728312492370605, 1.4787330627441406]], 'metadatas': [[{'Article Header': 'A far-sighted approach to machine learning'}, {'Article Header': 'Robot armies duke it out in Battlecode’s epic on-screen battles'}, {'Article Header': 'MIT professor to Congress: “We are at an inflection point” with AI'}, {'Article Header': 'If art is how we express our humanity, where does AI fit in?'}, {'Article Header': 'Bringing the social and ethical responsibilities of computing to the forefront'}, {'Article Header': 'Drones navigate unseen environments with liquid neural networks '}, {'Article Header': 'Ensuring AI works with the right dose of curiosity'}, {'Article Header': 'A four-legged robotic system for playing soccer on various terrains'}, {'Article Header': 'MIT CSAIL researchers discuss frontiers of generative AI '}, {'Article Header': 'Machine learning and the arts: A creative continuum'}]], 'embeddings': None, 'documents': [[\"['Picture two teams squaring off on a football field. The players can cooperate to achieve an objective, and compete against other players with conflicting interests. That’s how the game works.', '', 'Creating artificial intelligence agents that can learn to compete and cooperate as effectively as humans remains a thorny problem. A key challenge is enabling AI agents to anticipate future behaviors of other agents when they are all learning simultaneously.', '', 'Because of the complexity of this problem, current approaches tend to be myopic; the agents can only guess the next few moves of their teammates or competitors, which leads to poor performance in the long run.', '', 'Researchers from MIT, the MIT-IBM Watson AI Lab, and elsewhere have developed a new approach that gives AI agents a farsighted perspective. Their machine-learning framework enables cooperative or competitive AI agents to consider what other agents will do as time approaches infinity, not just over a few next steps. The agents then adapt their behaviors accordingly to influence other agents’ future behaviors and arrive at an optimal, long-term solution.', '', 'This framework could be used by a group of autonomous drones working together to find a lost hiker in a thick forest, or by self-driving cars that strive to keep passengers safe by anticipating future moves of other vehicles driving on a busy highway.', '', '“When AI agents are cooperating or competing, what matters most is when their behaviors converge at some point in the future. There are a lot of transient behaviors along the way that don’t matter very much in the long run. Reaching this converged behavior is what we really care about, and we now have a mathematical way to enable that,” says Dong-Ki Kim, a graduate student in the MIT Laboratory for Information and Decision Systems (LIDS) and lead author of a paper describing this framework.', '', 'The senior author is Jonathan P. How, the Richard C. Maclaurin Professor of Aeronautics and Astronautics and a member of the MIT-IBM Watson AI Lab. Co-authors include others at the MIT-IBM Watson AI Lab, IBM Research, Mila-Quebec Artificial Intelligence Institute, and Oxford University. The research will be presented at the Conference on Neural Information Processing Systems.', '']\", \"['In a packed room in MIT’s Stata Center, hundreds of digital robots collide across a giant screen projected at the front of the room. A crowd of students in the audience gasps and cheers as the battle’s outcome hangs in the balance. In an upper corner of the screen, the people who have programmed the robot armies’ strategies narrate the action in real time.', 'This isn’t the latest e-sports event, it’s MIT’s long-running Battlecode competition. Open to student teams around the world, Battlecode tasks participants with writing the code to program entire armies — not just individual bots — before they duke it out. The resulting dramatic, often-unexpected outcomes are decided based on whose programming strategy aligns best with the parameters of the game and the circumstances of the battle.', 'The unique competition pushes teams to spend hours coding and refining their armies in a quest for the perfectly crafted game plan. Since 2007, the competition has involved high school and college students from around the world, upping the intellectual ante as people with diverse backgrounds tackle the open-ended challenge.']\", \"['Government should not “abdicate” its responsibilities and leave the future path of artificial intelligence solely to Big Tech, Aleksander Mądry, the Cadence Design Systems Professor of Computing at MIT and director of the MIT Center for Deployable Machine Learning, told a Congressional panel on Wednesday.', 'Rather, Mądry said, government should be asking questions about the purpose and explainability of the algorithms corporations are using, as a precursor to regulation, which he described as “an important tool” in ensuring that AI is consistent with society’s goals. If the government doesn’t start asking questions, then “I am extremely worried” about the future of AI, Mądry said in response to a question from Rep. Gerald Connolly.', 'Mądry, a leading expert on explainability and AI, was testifying at a hearing titled “Advances in AI: Are We Ready for a Tech Revolution?” before the House Subcommittee on Cybersecurity, Information Technology, and Government Innovation, a panel of the House Committee on Government Reform and Oversight. The other witnesses at the hearing were former Google CEO Eric Schmidt, IBM Vice President Scott Crowder, and Center for AI and Digital Policy Senior Research Director Merve Hickok.', 'In her opening remarks, Subcommittee Chair Rep. Nancy Mace cited the book “The Age of AI: And Our Human Future” by Schmidt, Henry Kissinger, and Dan Huttenlocher, the dean of the MIT Schwarzman College of Computing. She also called attention to a March 3 op-ed in The Wall Street Journal by the three authors that summarized the book while discussing ChatGPT. Mace said her formal opening remarks had been entirely written by ChatGPT.', 'In his prepared remarks, Mądry raised three overarching points. First, he noted that AI is “no longer a matter of science fiction” or confined to research labs. It is out in the world, where it can bring enormous benefits but also poses risks.', 'Second, he said AI exposes us to “interactions that go against our intuition.” He said because AI tools like ChatGPT mimic human communication, people are too likely to unquestioningly believe what such large language models produce. In the worst case, Mądry warned, human analytical skills will atrophy. He also said it would be a mistake to regulate AI as if it were human — for example, by asking AI to explain its reasoning and assuming that the resulting answers are credible.', 'Finally, he said too little attention has been paid to problems that will result from the nature of the AI “supply chain” — the way AI systems are built on top of each other. At the base are general systems like ChatGPT, which can be developed by only a few companies because they are so expensive and complex to build. Layered on top of such systems are many AI systems designed to handle a particular task, like figuring out whom a company should hire.', 'Mądry said this layering raised several “policy-relevant” concerns. First, the entire system of AI is subject to whatever vulnerabilities or biases are in the large system at its base, and is dependent on the work of a few, large companies. Second, the interaction of AI systems is not well-understood from a technical standpoint, making the results of AI even more difficult to predict or explain, and making the tools difficult to “audit.” Finally, the mix of AI tools makes it difficult to know whom to hold responsible when a problem results — who should be legally liable and who should address the concern.', 'In the written material submitted to the subcommittee, Mądry concluded, “AI technology is not particularly well-suited for deployment through complex supply chains,” even though that is exactly how it is being deployed.', 'Mądry ended his testimony by calling on Congress to probe AI issues and to be prepared to act. “We are at an inflection point in terms of what future AI will bring. Seizing this opportunity means discussing the role of AI, what exactly we want it to do for us, and how to ensure it benefits us all. This will be a difficult conversation but we do need to have it, and have it now,” he told the subcommittee.', 'The testimony of all the hearing witnesses and a video of the hearing, which lasted about two hours, is available online.']\", '[\\'The rapid advance of artificial intelligence has generated a lot of buzz, with some predicting it will lead to an idyllic utopia and others warning it will bring the end of humanity. But speculation about where AI technology is going, while important, can also drown out important conversations about how we should be handling the AI technologies available today.\\', \\'One such technology is generative AI, which can create content including text, images, audio, and video. Popular generative AIs like the chatbot ChatGPT generate conversational text based on training data taken from the internet.\\', \\'Today a group of 14 researchers from a number of organizations including MIT published a commentary article in Science that helps set the stage for discussions about generative AI’s immediate impact on creative work and society more broadly. The paper’s MIT-affiliated co-authors include Media Lab postdoc Ziv Epstein SM ’19, PhD ’23; Matt Groh SM ’19, PhD ’23; PhD students Rob Mahari ’17 and Hope Schroeder; and Professor Alex \"Sandy\" Pentland.\\', \\'MIT News spoke with Epstein, the lead author of the paper.\\', \\'Q: Why did you write this paper?\\', \\'A: Generative AI tools are doing things that even a few years ago we never thought would be possible. This raises a lot of fundamental questions about the creative process and the human’s role in creative production. Are we going to get automated out of jobs? How are we going to preserve the human aspect of creativity with all of these new technologies?\\', \\'The complexity of black-box AI systems can make it hard for researchers and the broader public to understand what’s happening under the hood, and what the impacts of these tools on society will be. Many discussions about AI anthropomorphize the technology, implicitly suggesting these systems exhibit human-like intent, agency, or self-awareness. Even the term “artificial intelligence” reinforces these beliefs: ChatGPT uses first-person pronouns, and we say AIs “hallucinate.” These agentic roles we give AIs can undermine the credit to creators whose labor underlies the system’s outputs, and can deflect responsibility from the developers and decision makers when the systems cause harm.\\', \\'We’re trying to build coalitions across academia and beyond to help think about the interdisciplinary connections and research areas necessary to grapple with the immediate dangers to humans coming from the deployment of these tools, such as disinformation, job displacement, and changes to legal structures and culture.\\', \\'Q: What do you see as the gaps in research around generative AI and art today?\\', \\'A: The way we talk about AI is broken in many ways. We need to understand how perceptions of the generative process affect attitudes toward outputs and authors, and also design the interfaces and systems in a way that is really transparent about the generative process and avoids some of these misleading interpretations. How do we talk about AI and how do these narratives cut along lines of power? As we outline in the article, there are these themes around AI’s impact that are important to consider: aesthetics and culture; legal aspects of ownership and credit; labor; and the impacts to the media ecosystem. For each of those we highlight the big open questions.\\', \\'With aesthetics and culture, we’re considering how past art technologies can inform how we think about AI. For example, when photography was invented, some painters said it was “the end of art.” But instead it ended up being its own medium and eventually liberated painting from realism, giving rise to Impressionism and the modern art movement. We’re saying generative AI is a medium with its own affordances. The nature of art will evolve with that. How will artists and creators express their intent and style through this new medium?\\', \\'Issues around ownership and credit are tricky because we need copyright law that benefits creators, users, and society at large. Today’s copyright laws might not adequately apportion rights to artists when these systems are training on their styles. When it comes to training data, what does it mean to copy? That’s a legal question, but also a technical question. We’re trying to understand if these systems are copying, and when.\\', \\'For labor economics and creative work, the idea is these generative AI systems can accelerate the creative process in many ways, but they can also remove the ideation process that starts with a blank slate. Sometimes, there’s actually good that comes from starting with a blank page. We don’t know how it’s going to influence creativity, and we need a better understanding of how AI will affect the different stages of the creative process. We need to think carefully about how we use these tools to complement people’s work instead of replacing it.\\', \\'In terms of generative AI’s effect on the media ecosystem, with the ability to produce synthetic media at scale, the risk of AI-generated misinformation must be considered. We need to safeguard the media ecosystem against the possibility of massive fraud on one hand, and people losing trust in real media on the other.\\', \\'Q: How do you hope this paper is received — and by whom?\\', \\'A: The conversation about AI has been very fragmented and frustrating. Because the technologies are moving so fast, it’s been hard to think deeply about these ideas. To ensure the beneficial use of these technologies, we need to build shared language and start to understand where to focus our attention. We’re hoping this paper can be a step in that direction. We’re trying to start a conversation that can help us build a roadmap toward understanding this fast-moving situation.\\', \\'Artists many times are at the vanguard of new technologies. They’re playing with the technology long before there are commercial applications. They’re exploring how it works, and they’re wrestling with the ethics of it. AI art has been going on for over a decade, and for as long these artists have been grappling with the questions we now face as a society. I think it is critical to uplift the voices of the artists and other creative laborers whose jobs will be impacted by these tools. Art is how we express our humanity. It’s a core human, emotional part of life. In that way we believe it’s at the center of broader questions about AI’s impact on society, and hopefully we can ground that discussion with this.\\']', '[\\'There has been a remarkable surge in the use of algorithms and artificial intelligence to address a wide range of problems and challenges. While their adoption, particularly with the rise of AI, is reshaping nearly every industry sector, discipline, and area of research, such innovations often expose unexpected consequences that involve new norms, new expectations, and new rules and laws.\\', \\'To facilitate deeper understanding, the Social and Ethical Responsibilities of Computing (SERC), a cross-cutting initiative in the MIT Schwarzman College of Computing, recently brought together social scientists and humanists with computer scientists, engineers, and other computing faculty for an exploration of the ways in which the broad applicability of algorithms and AI has presented both opportunities and challenges in many aspects of society.\\', \\'“The very nature of our reality is changing. AI has the ability to do things that until recently were solely the realm of human intelligence — things that can challenge our understanding of what it means to be human,” remarked Daniel Huttenlocher, dean of the MIT Schwarzman College of Computing, in his opening address at the inaugural SERC Symposium. “This poses philosophical, conceptual, and practical questions on a scale not experienced since the start of the Enlightenment. In the face of such profound change, we need new conceptual maps for navigating the change.”\\', \\'The symposium offered a glimpse into the vision and activities of SERC in both research and education. “We believe our responsibility with SERC is to educate and equip our students and enable our faculty to contribute to responsible technology development and deployment,” said Georgia Perakis, the William F. Pounds Professor of Management in the MIT Sloan School of Management, co-associate dean of SERC, and the lead organizer of the symposium. “We’re drawing from the many strengths and diversity of disciplines across MIT and beyond and bringing them together to gain multiple viewpoints.”\\', \\'Through a succession of panels and sessions, the symposium delved into a variety of topics related to the societal and ethical dimensions of computing. In addition, 37 undergraduate and graduate students from a range of majors, including urban studies and planning, political science, mathematics, biology, electrical engineering and computer science, and brain and cognitive sciences, participated in a poster session to exhibit their research in this space, covering such topics as quantum ethics, AI collusion in storage markets, computing waste, and empowering users on social platforms for better content credibility.\\', \\'Showcasing a diversity of work\\', \\'In three sessions devoted to themes of beneficent and fair computing, equitable and personalized health, and algorithms and humans, the SERC Symposium showcased work by 12 faculty members across these domains.\\', \\'One such project from a multidisciplinary team of archaeologists, architects, digital artists, and computational social scientists aimed to preserve endangered heritage sites in Afghanistan with digital twins. The project team produced highly detailed interrogable 3D models of the heritage sites, in addition to extended reality and virtual reality experiences, as learning resources for audiences that cannot access these sites.\\', \\'In a project for the United Network for Organ Sharing, researchers showed how they used applied analytics to optimize various facets of an organ allocation system in the United States that is currently undergoing a major overhaul in order to make it more efficient, equitable, and inclusive for different racial, age, and gender groups, among others.\\', \\'Another talk discussed an area that has not yet received adequate public attention: the broader implications for equity that biased sensor data holds for the next generation of models in computing and health care.\\', \\'A talk on bias in algorithms considered both human bias and algorithmic bias, and the potential for improving results by taking into account differences in the nature of the two kinds of bias.\\', \\'Other highlighted research included the interaction between online platforms and human psychology; a study on whether decision-makers make systemic prediction mistakes on the available information; and an illustration of how advanced analytics and computation can be leveraged to inform supply chain management, operations, and regulatory work in the food and pharmaceutical industries.\\', \\'Improving the algorithms of tomorrow\\', \\'“Algorithms are, without question, impacting every aspect of our lives,” said Asu Ozdaglar, deputy dean of academics for the MIT Schwarzman College of Computing and head of the Department of Electrical Engineering and Computer Science, in kicking off a panel she moderated on the implications of data and algorithms.\\', \\'“Whether it’s in the context of social media, online commerce, automated tasks, and now a much wider range of creative interactions with the advent of generative AI tools and large language models, there’s little doubt that much more is to come,” Ozdaglar said. “While the promise is evident to all of us, there’s a lot to be concerned as well. This is very much time for imaginative thinking and careful deliberation to improve the algorithms of tomorrow.”\\', \\'Turning to the panel, Ozdaglar asked experts from computing, social science, and data science for insights on how to understand what is to come and shape it to enrich outcomes for the majority of humanity.\\', \\'Sarah Williams, associate professor of technology and urban planning at MIT, emphasized the critical importance of comprehending the process of how datasets are assembled, as data are the foundation for all models. She also stressed the need for research to address the potential implication of biases in algorithms that often find their way in through their creators and the data used in their development. “It’s up to us to think about our own ethical solutions to these problems,” she said. “Just as it’s important to progress with the technology, we need to start the field of looking at these questions of what biases are in the algorithms? What biases are in the data, or in that data’s journey?”\\', \\'Shifting focus to generative models and whether the development and use of these technologies should be regulated, the panelists — which also included MIT’s Srini Devadas, professor of electrical engineering and computer science, John Horton, professor of information technology, and Simon Johnson, professor of entrepreneurship — all concurred that regulating open-source algorithms, which are publicly accessible, would be difficult given that regulators are still catching up and struggling to even set guardrails for technology that is now 20 years old.\\', \"Returning to the question of how to effectively regulate the use of these technologies, Johnson proposed a progressive corporate tax system as a potential solution. He recommends basing companies\\' tax payments on their profits, especially for large corporations whose massive earnings go largely untaxed due to offshore banking. By doing so, Johnson said that this approach can serve as a regulatory mechanism that discourages companies from trying to “own the entire world” by imposing disincentives.\", \\'The role of ethics in computing education\\', \\'As computing continues to advance with no signs of slowing down, it is critical to educate students to be intentional in the social impact of the technologies they will be developing and deploying into the world. But can one actually be taught such things? If so, how?\\', \\'Caspar Hare, professor of philosophy at MIT and co-associate dean of SERC, posed this looming question to faculty on a panel he moderated on the role of ethics in computing education. All experienced in teaching ethics and thinking about the social implications of computing, each panelist shared their perspective and approach.\\', \\'A strong advocate for the importance of learning from history, Eden Medina, associate professor of science, technology, and society at MIT, said that “often the way we frame computing is that everything is new. One of the things that I do in my teaching is look at how people have confronted these issues in the past and try to draw from them as a way to think about possible ways forward.” Medina regularly uses case studies in her classes and referred to a paper written by Yale University science historian Joanna Radin on the Pima Indian Diabetes Dataset that raised ethical issues on the history of that particular collection of data that many don’t consider as an example of how decisions around technology and data can grow out of very specific contexts.\\', \\'Milo Phillips-Brown, associate professor of philosophy at Oxford University, talked about the Ethical Computing Protocol that he co-created while he was a SERC postdoc at MIT. The protocol, a four-step approach to building technology responsibly, is designed to train computer science students to think in a better and more accurate way about the social implications of technology by breaking the process down into more manageable steps. “The basic approach that we take very much draws on the fields of value-sensitive design, responsible research and innovation, participatory design as guiding insights, and then is also fundamentally interdisciplinary,” he said.\\', \\'Fields such as biomedicine and law have an ethics ecosystem that distributes the function of ethical reasoning in these areas. Oversight and regulation are provided to guide front-line stakeholders and decision-makers when issues arise, as are training programs and access to interdisciplinary expertise that they can draw from. “In this space, we have none of that,” said John Basl, associate professor of philosophy at Northeastern University. “For current generations of computer scientists and other decision-makers, we’re actually making them do the ethical reasoning on their own.” Basl commented further that teaching core ethical reasoning skills across the curriculum, not just in philosophy classes, is essential, and that the goal shouldn’t be for every computer scientist be a professional ethicist, but for them to know enough of the landscape to be able to ask the right questions and seek out the relevant expertise and resources that exists.\\', \\'After the final session, interdisciplinary groups of faculty, students, and researchers engaged in animated discussions related to the issues covered throughout the day during a reception that marked the conclusion of the symposium.\\']', '[\\'In the vast, expansive skies where birds once ruled supreme, a new crop of aviators is taking flight. These pioneers of the air are not living creatures, but rather a product of deliberate innovation: drones. But these aren’t your typical flying bots, humming around like mechanical bees. Rather, they’re avian-inspired marvels that soar through the sky, guided by liquid neural networks to navigate ever-changing and unseen environments with precision and ease.\\', \\'Inspired by the adaptable nature of organic brains, researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) have introduced a method for robust flight navigation agents to master vision-based fly-to-target tasks in intricate, unfamiliar environments. The liquid neural networks, which can continuously adapt to new data inputs, showed prowess in making reliable decisions in unknown domains like forests, urban landscapes, and environments with added noise, rotation, and occlusion. These adaptable models, which outperformed many state-of-the-art counterparts in navigation tasks, could enable potential real-world drone applications like search and rescue, delivery, and wildlife monitoring.\\', \"The researchers\\' recent study, published today in Science Robotics, details how this new breed of agents can adapt to significant distribution shifts, a long-standing challenge in the field. The team’s new class of machine-learning algorithms, however, captures the causal structure of tasks from high-dimensional, unstructured data, such as pixel inputs from a drone-mounted camera. These networks can then extract crucial aspects of a task (i.e., understand the task at hand) and ignore irrelevant features, allowing acquired navigation skills to transfer targets seamlessly to new environments.\"]', '[\"It’s a dilemma as old as time. Friday night has rolled around, and you’re trying to pick a restaurant for dinner. Should you visit your most beloved watering hole or try a new establishment, in the hopes of discovering something superior? Potentially, but that curiosity comes with a risk: If you explore the new option, the food could be worse. On the flip side, if you stick with what you know works well, you won\\'t grow out of your narrow pathway.\", \\'Curiosity drives artificial intelligence to explore the world, now in boundless use cases — autonomous navigation, robotic decision-making, optimizing health outcomes, and more. Machines, in some cases, use “reinforcement learning” to accomplish a goal, where an AI agent iteratively learns from being rewarded for good behavior and punished for bad. Just like the dilemma faced by humans in selecting a restaurant, these agents also struggle with balancing the time spent discovering better actions (exploration) and the time spent taking actions that led to high rewards in the past (exploitation). Too much curiosity can distract the agent from making good decisions, while too little means the agent will never discover good decisions.\\', \"In the pursuit of making AI agents with just the right dose of curiosity, researchers from MIT’s Improbable AI Laboratory and Computer Science and Artificial Intelligence Laboratory (CSAIL) created an algorithm that overcomes the problem of AI being too “curious” and getting distracted by a given task. Their algorithm automatically increases curiosity when it\\'s needed, and suppresses it if the agent gets enough supervision from the environment to know what to do.\", \\'When tested on over 60 video games, the algorithm was able to succeed at both hard and easy exploration tasks, where previous algorithms have only been able to tackle only a hard or easy domain alone. With this method, AI agents use fewer data for learning decision-making rules that maximize incentives.\\', \"“If you master the exploration-exploitation trade-off well, you can learn the right decision-making rules faster — and anything less will require lots of data, which could mean suboptimal medical treatments, lesser profits for websites, and robots that don\\'t learn to do the right thing,” says Pulkit Agrawal, an assistant professor of electrical engineering and computer science (EECS) at MIT, director of the Improbable AI Lab, and CSAIL affiliate who supervised the research. “Imagine a website trying to figure out the design or layout of its content that will maximize sales. If one doesn’t perform exploration-exploitation well, converging to the right website design or the right website layout will take a long time, which means profit loss. Or in a health care setting, like with Covid-19, there may be a sequence of decisions that need to be made to treat a patient, and if you want to use decision-making algorithms, they need to learn quickly and efficiently — you don\\'t want a suboptimal solution when treating a large number of patients. We hope that this work will apply to real-world problems of that nature.”\", \\'It’s hard to encompass the nuances of curiosity’s psychological underpinnings; the underlying neural correlates of challenge-seeking behavior are a poorly understood phenomenon. Attempts to categorize the behavior have spanned studies that dived deeply into studying our impulses, deprivation sensitivities, and social and stress tolerances.\\', \\'With reinforcement learning, this process is “pruned” emotionally and stripped down to the bare bones, but it’s complicated on the technical side. Essentially, the agent should only be curious when there’s not enough supervision available to try out different things, and if there is supervision, it must adjust curiosity and lower it.\\', \\'Since a large subset of gaming is little agents running around fantastical environments looking for rewards and performing a long sequence of actions to achieve some goal, it seemed like the logical test bed for the researchers’ algorithm. In experiments, researchers divided games like “Mario Kart” and “Montezuma’s Revenge” into two different buckets: one where supervision was sparse, meaning the agent had less guidance, which were considered “hard” exploration games, and a second where supervision was more dense, or the “easy” exploration games.\\', \\'Suppose in “Mario Kart,” for example, you only remove all rewards so you don’t know when an enemy eliminates you. You’re not given any reward when you collect a coin or jump over pipes. The agent is only told in the end how well it did. This would be a case of sparse supervision. Algorithms that incentivize curiosity do really well in this scenario.\\', \\'But now, suppose the agent is provided dense supervision — a reward for jumping over pipes, collecting coins, and eliminating enemies. Here, an algorithm without curiosity performs really well because it gets rewarded often. But if you instead take the algorithm that also uses curiosity, it learns slowly. This is because the curious agent might attempt to run fast in different ways, dance around, go to every part of the game screen — things that are interesting, but do not help the agent succeed at the game. The team’s algorithm, however, consistently performed well, irrespective of what environment it was in.\\', \\'Future work might involve circling back to the exploration that’s delighted and plagued psychologists for years: an appropriate metric for curiosity — no one really knows the right way to mathematically define curiosity.\\', \\'“Getting consistent good performance on a novel problem is extremely challenging — so by improving exploration algorithms, we can save your effort on tuning an algorithm for your problems of interest, says Zhang-Wei Hong, an EECS PhD student, CSAIL affiliate, and co-lead author along with Eric Chen\\\\xa0’20, MEng\\\\xa0’21 on a new paper about the work. “We need curiosity to solve extremely challenging problems, but on some problems it can hurt performance. We propose an algorithm that removes the burden of tuning the balance of exploration and exploitation. Previously what took, for instance, a week to successfully solve the problem, with this new algorithm, we can get satisfactory results in a few hours.”\\', \\'“One of the greatest challenges for current AI and cognitive science is how to balance exploration and exploitation — the search for information versus the search for reward. Children do this seamlessly, but it is challenging computationally,” notes Alison Gopnik, professor of psychology and affiliate professor of philosophy at the University of California at Berkeley, who was not involved with the project. “This paper uses impressive new techniques to accomplish this automatically, designing an agent that can systematically balance curiosity about the world and the desire for reward, [thus taking] another step towards making AI agents (almost) as smart as children.”\\', \\'“Intrinsic rewards like curiosity are fundamental to guiding agents to discover useful diverse behaviors, but this shouldn’t come at the cost of doing well at the given task. This is an important problem in AI, and the paper provides a way to balance that trade-off,” adds Deepak Pathak, an assistant professor at Carnegie Mellon University, who was also not involved in the work.\\\\xa0“It would be interesting to see how such methods scale beyond games to real-world robotic agents.”\\', \\'Chen, Hong, and Agrawal wrote the paper alongside Joni Pajarinen, assistant professor at Aalto University and research leader at the Intelligent Autonomous Systems Group at TU Darmstadt. The research was supported, in part, by the MIT-IBM Watson AI Lab, DARPA Machine Common Sense Program, the Army Research Office by the United States Air Force Research Laboratory, and the United States Air Force Artificial Intelligence Accelerator. The paper will be presented at Neural Information and Processing Systems (NeurIPS) 2022.\\']', '[\"If you\\'ve ever played soccer with a robot, it\\'s a familiar feeling. Sun glistens down on your face as the smell of grass permeates the air. You look around. A four-legged robot is hustling toward you, dribbling with determination.\", \\'While the bot doesn’t display a Lionel Messi-like level of ability, it\\\\\\'s an impressive in-the-wild dribbling system nonetheless. Researchers from MIT\\\\\\'s Improbable Artificial Intelligence Lab, part of the Computer Science and Artificial Intelligence Laboratory (CSAIL), have developed a legged robotic system that can dribble a soccer ball under the same conditions as humans. The bot used a mixture of onboard sensing and computing to traverse different natural terrains such as sand, gravel, mud, and snow, and adapt to their varied impact on the ball’s motion. Like every committed athlete, \"DribbleBot\" could get up and recover the ball after falling.\\', \\'Programming robots to play soccer has been an active research area for some time. However, the team wanted to automatically learn how to actuate the legs during dribbling, to enable the discovery of hard-to-script skills for responding to diverse terrains like snow, gravel, sand, grass, and pavement. Enter, simulation.\\', \"A robot, ball, and terrain are inside the simulation\\\\xa0— a digital twin of the natural world. You can load in the bot and other assets and set physics parameters, and then it handles the forward simulation of the dynamics from there. Four thousand versions of the robot are simulated in parallel in real time, enabling data collection 4,000 times faster than using just one robot. That\\'s a lot of data.\"]', '[\\'The emergence of generative artificial intelligence has ignited a deep philosophical exploration into the nature of consciousness, creativity, and authorship. As we bear witness to new advances in the field, it’s increasingly apparent that these synthetic agents possess a remarkable capacity to create, iterate, and challenge our traditional notions of intelligence. But what does it really mean for an AI system to be “generative,” with newfound blurred boundaries of creative expression between humans and machines?\\', \"For those who feel as if “generative artificial intelligence”\\\\xa0— a type of AI that can cook up new and original data or content similar to what it\\'s been trained on — cascaded into existence like an overnight sensation, while indeed the new capabilities have surprised many, the underlying technology has been in the making for some time.\", \\'But understanding true capacity can be as indistinct as some of the generative content these models produce. To that end, researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) convened in discussions around the capabilities and limitations of generative AI, as well as its potential impacts on society and industries, with regard to language, images, and code.\\', \\'There are various models of generative AI, each with their own unique approaches and techniques. These include generative adversarial networks (GANs), variational autoencoders (VAEs), and diffusion models, which have all shown off exceptional power in various industries and fields, from art to music and medicine. With that has also come a slew of ethical and social conundrums, such as the potential for generating fake news, deepfakes, and misinformation. Making these considerations is critical, the researchers say, to continue studying the capabilities and limitations of generative AI and ensure ethical use and responsibility.\\', \\'During opening remarks, to illustrate visual prowess of these models, MIT professor of electrical engineering and computer science (EECS) and CSAIL Director Daniela Rus pulled out a special gift her students recently bestowed upon her: a collage of AI portraits ripe with smiling shots of Rus, running a spectrum of mirror-like reflections. Yet, there was no commissioned artist in sight.\\', \\'The machine was to thank.\\', \\'Generative models learn to make imagery by downloading many photos from the internet and trying to make the output image look like the sample training data. There are many ways to train a neural network generator, and diffusion models are just one popular way. These models, explained by MIT associate professor of EECS and CSAIL principal investigator Phillip Isola, map from random noise to imagery. Using a process called diffusion, the model will convert structured objects like images into random noise, and the process is inverted by training a neural net to remove noise step by step until that noiseless image is obtained. If you’ve ever tried a hand at using DALL-E 2, where a sentence and random noise are input, and the noise congeals into images, you’ve used a diffusion model.\\']', \"['Sketch a doodle of a drum or a saxophone to conjure a multi-instrumental composition. Look into a webcam, speak, and watch your mouth go bouncing across the screen — the input for a series of charmingly clunky chain reactions.', 'This is what visitors to the MIT Lewis Music Library encounter when they interact with two new digital installations, “Doodle Tunes” and “Sounds from the Mouth,” created by 2022-23 Center for Art and Technology (CAST) Visiting Artist Andreas Refsgaard in collaboration with Music Technology and Digital Media Librarian Caleb Hall. The residency was initiated by Avery Boddie, Lewis Music Library department head, who recognized Refsgaard’s flair for revealing the playfulness of emerging technologies. The intricacies of coding and machine learning can seem daunting to newcomers, but Refsgaard’s practice as a creative coder, interaction designer, and educator seeks to open the field to all. Encompassing workshops, an artist talk, class visits, and an exhibition, the residency was infused with his unique sense of humor — a combination of lively eccentricity and easygoing relatability.']\"]], 'uris': None, 'data': None}\n"
          ]
        }
      ],
      "source": [
        "results = collection.query(query_texts=[\"agent\"], n_results=10 )\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31fed3db",
      "metadata": {
        "papermill": {
          "duration": 0.02373,
          "end_time": "2024-02-21T15:59:53.281923",
          "exception": false,
          "start_time": "2024-02-21T15:59:53.258193",
          "status": "completed"
        },
        "tags": [],
        "id": "31fed3db"
      },
      "source": [
        "## Vector MAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "f5ed54f5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T15:59:53.32661Z",
          "iopub.status.busy": "2024-02-21T15:59:53.326026Z",
          "iopub.status.idle": "2024-02-21T15:59:54.903831Z",
          "shell.execute_reply": "2024-02-21T15:59:54.902702Z"
        },
        "papermill": {
          "duration": 1.602967,
          "end_time": "2024-02-21T15:59:54.906788",
          "exception": false,
          "start_time": "2024-02-21T15:59:53.303821",
          "status": "completed"
        },
        "tags": [],
        "id": "f5ed54f5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "da0b01dd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T15:59:54.951484Z",
          "iopub.status.busy": "2024-02-21T15:59:54.950337Z",
          "iopub.status.idle": "2024-02-21T15:59:54.959898Z",
          "shell.execute_reply": "2024-02-21T15:59:54.958653Z"
        },
        "papermill": {
          "duration": 0.034729,
          "end_time": "2024-02-21T15:59:54.962541",
          "exception": false,
          "start_time": "2024-02-21T15:59:54.927812",
          "status": "completed"
        },
        "tags": [],
        "id": "da0b01dd"
      },
      "outputs": [],
      "source": [
        "\n",
        "getado = collection.get(ids=\"id92\",\n",
        "                       include=[\"documents\", \"embeddings\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "e24e00a5",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2024-02-21T15:59:55.004646Z",
          "iopub.status.busy": "2024-02-21T15:59:55.004104Z",
          "iopub.status.idle": "2024-02-21T15:59:55.01893Z",
          "shell.execute_reply": "2024-02-21T15:59:55.017526Z"
        },
        "papermill": {
          "duration": 0.0397,
          "end_time": "2024-02-21T15:59:55.022025",
          "exception": false,
          "start_time": "2024-02-21T15:59:54.982325",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e24e00a5",
        "outputId": "953ac58f-da72-49b1-9abd-bed3fb623180"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.04226541891694069,\n",
              "  -0.0212083887308836,\n",
              "  0.03742208331823349,\n",
              "  0.06610095500946045,\n",
              "  0.03664502874016762,\n",
              "  -0.0007144288392737508,\n",
              "  0.05554430931806564,\n",
              "  0.03048654831945896,\n",
              "  0.01930970698595047,\n",
              "  0.07292573899030685,\n",
              "  -0.03171218931674957,\n",
              "  0.01608399488031864,\n",
              "  -0.0016827037325128913,\n",
              "  0.0194687657058239,\n",
              "  0.021139102056622505,\n",
              "  -0.0304621160030365,\n",
              "  0.0559379905462265,\n",
              "  -0.04413607716560364,\n",
              "  -0.13791915774345398,\n",
              "  -0.042626842856407166,\n",
              "  -0.021961914375424385,\n",
              "  -0.03184959664940834,\n",
              "  0.022369278594851494,\n",
              "  -0.014555440284311771,\n",
              "  -0.11748731881380081,\n",
              "  0.005123821087181568,\n",
              "  0.03719363361597061,\n",
              "  -0.06350752711296082,\n",
              "  0.010708615183830261,\n",
              "  -0.04293955862522125,\n",
              "  0.055304545909166336,\n",
              "  0.022111039608716965,\n",
              "  0.08792227506637573,\n",
              "  -0.05349726974964142,\n",
              "  -0.04119262099266052,\n",
              "  0.052483391016721725,\n",
              "  -0.05847429484128952,\n",
              "  -0.04299667850136757,\n",
              "  0.0361599400639534,\n",
              "  -0.03068520687520504,\n",
              "  0.012027139775454998,\n",
              "  -0.03745385631918907,\n",
              "  0.020498568192124367,\n",
              "  0.02401605434715748,\n",
              "  0.09077105671167374,\n",
              "  0.03327089548110962,\n",
              "  0.02978813275694847,\n",
              "  -0.10107722133398056,\n",
              "  0.051255133002996445,\n",
              "  -0.036449916660785675,\n",
              "  -0.1038651242852211,\n",
              "  -0.02075878530740738,\n",
              "  -0.04209716618061066,\n",
              "  -0.007413842715322971,\n",
              "  -0.024443432688713074,\n",
              "  0.01814967952668667,\n",
              "  -0.021676037460565567,\n",
              "  0.05969959497451782,\n",
              "  -0.0005364188109524548,\n",
              "  -0.058959878981113434,\n",
              "  0.06966230273246765,\n",
              "  -0.12574931979179382,\n",
              "  0.06097681447863579,\n",
              "  0.0028337030671536922,\n",
              "  0.04556984081864357,\n",
              "  -0.0193604975938797,\n",
              "  -0.038628920912742615,\n",
              "  -0.014074970968067646,\n",
              "  0.031218471005558968,\n",
              "  -0.032799314707517624,\n",
              "  0.054529622197151184,\n",
              "  0.0062822201289236546,\n",
              "  -0.0010283265728503466,\n",
              "  0.020173916593194008,\n",
              "  0.01862514764070511,\n",
              "  -0.04926343634724617,\n",
              "  0.037883464246988297,\n",
              "  -0.06878957152366638,\n",
              "  0.056446388363838196,\n",
              "  0.028794163838028908,\n",
              "  -0.01150159165263176,\n",
              "  -0.03634202107787132,\n",
              "  -0.06175609305500984,\n",
              "  0.09550102055072784,\n",
              "  -0.003168684896081686,\n",
              "  -0.044990066438913345,\n",
              "  0.039613816887140274,\n",
              "  -0.031413640826940536,\n",
              "  0.13025063276290894,\n",
              "  -0.031224630773067474,\n",
              "  0.03326490893959999,\n",
              "  -0.0723709911108017,\n",
              "  -0.05451897531747818,\n",
              "  -0.023192135617136955,\n",
              "  0.07230312377214432,\n",
              "  0.05882912874221802,\n",
              "  -0.053430091589689255,\n",
              "  -0.10556171089410782,\n",
              "  -0.08053062111139297,\n",
              "  0.016125589609146118,\n",
              "  0.03264397755265236,\n",
              "  0.04061552882194519,\n",
              "  -0.007982833310961723,\n",
              "  0.04497726634144783,\n",
              "  0.01849519833922386,\n",
              "  0.00879995059221983,\n",
              "  0.008037631399929523,\n",
              "  0.003159839427098632,\n",
              "  0.0868055671453476,\n",
              "  -0.030847325921058655,\n",
              "  -0.039224158972501755,\n",
              "  0.02635156735777855,\n",
              "  0.08643017709255219,\n",
              "  0.0068587930873036385,\n",
              "  -0.017188960686326027,\n",
              "  0.01047554612159729,\n",
              "  -0.02026449888944626,\n",
              "  0.04899021238088608,\n",
              "  -0.004033589735627174,\n",
              "  0.09377561509609222,\n",
              "  -0.014342518523335457,\n",
              "  -0.0732734277844429,\n",
              "  -0.03557995334267616,\n",
              "  -0.015997646376490593,\n",
              "  0.0003332480264361948,\n",
              "  -0.016526956111192703,\n",
              "  -0.008304174989461899,\n",
              "  4.0788059709320074e-33,\n",
              "  -0.03595538064837456,\n",
              "  -0.03788505122065544,\n",
              "  0.04613909125328064,\n",
              "  0.021962400525808334,\n",
              "  0.04859587922692299,\n",
              "  -0.0418693944811821,\n",
              "  0.04181959107518196,\n",
              "  0.03106292150914669,\n",
              "  0.025536518543958664,\n",
              "  0.03535333648324013,\n",
              "  0.04541589319705963,\n",
              "  -0.025962723419070244,\n",
              "  -0.03191075474023819,\n",
              "  0.027603277936577797,\n",
              "  0.05838435888290405,\n",
              "  -0.0628291592001915,\n",
              "  -0.08526746183633804,\n",
              "  -0.033232804387807846,\n",
              "  0.039624109864234924,\n",
              "  -0.04592801630496979,\n",
              "  0.05868889391422272,\n",
              "  -0.06194126233458519,\n",
              "  0.015479892492294312,\n",
              "  -0.004598728381097317,\n",
              "  0.03879278153181076,\n",
              "  -0.011206063441932201,\n",
              "  0.029818328097462654,\n",
              "  -0.040100082755088806,\n",
              "  0.0035620906855911016,\n",
              "  -0.027693867683410645,\n",
              "  -0.04522644728422165,\n",
              "  0.09637451171875,\n",
              "  -0.09146764874458313,\n",
              "  0.016874415799975395,\n",
              "  -0.004324690904468298,\n",
              "  0.03873478248715401,\n",
              "  -0.05650419741868973,\n",
              "  0.04624888300895691,\n",
              "  0.016791919246315956,\n",
              "  -0.01393839716911316,\n",
              "  -0.04219071939587593,\n",
              "  0.033195991069078445,\n",
              "  0.07606322318315506,\n",
              "  -0.00839462410658598,\n",
              "  -0.0036135136615484953,\n",
              "  -0.03707515820860863,\n",
              "  0.0829460397362709,\n",
              "  -0.10449527949094772,\n",
              "  -0.1222977563738823,\n",
              "  0.014085561037063599,\n",
              "  -0.034105997532606125,\n",
              "  0.018365178257226944,\n",
              "  0.023972252383828163,\n",
              "  -0.07995706796646118,\n",
              "  0.006159517448395491,\n",
              "  -0.0028522005304694176,\n",
              "  0.022429047152400017,\n",
              "  -0.0050294711254537106,\n",
              "  -0.012751600705087185,\n",
              "  -0.010937911458313465,\n",
              "  0.06456230580806732,\n",
              "  -0.04358683526515961,\n",
              "  -0.007124399300664663,\n",
              "  0.07938355207443237,\n",
              "  0.07184342294931412,\n",
              "  0.07713349908590317,\n",
              "  0.09141553938388824,\n",
              "  0.023765500634908676,\n",
              "  0.025556989014148712,\n",
              "  0.0701257735490799,\n",
              "  0.011119076050817966,\n",
              "  0.027876336127519608,\n",
              "  -0.04815470427274704,\n",
              "  -0.1411891132593155,\n",
              "  -0.005702098831534386,\n",
              "  -0.002042054198682308,\n",
              "  0.013118346221745014,\n",
              "  -0.06715639680624008,\n",
              "  0.061864469200372696,\n",
              "  -0.07438233494758606,\n",
              "  -0.011246590875089169,\n",
              "  -0.0016388160875067115,\n",
              "  -0.04414420202374458,\n",
              "  0.06521007418632507,\n",
              "  -0.026060771197080612,\n",
              "  -0.0011161150177940726,\n",
              "  -0.024882594123482704,\n",
              "  -0.07467697560787201,\n",
              "  0.04637154936790466,\n",
              "  0.031685441732406616,\n",
              "  -0.07133439183235168,\n",
              "  0.031324706971645355,\n",
              "  0.010719704441726208,\n",
              "  0.07115060836076736,\n",
              "  -0.022405477240681648,\n",
              "  -3.526145465182986e-33,\n",
              "  0.007153581362217665,\n",
              "  -0.1075892448425293,\n",
              "  0.018638070672750473,\n",
              "  0.06143306568264961,\n",
              "  -0.005226581357419491,\n",
              "  -0.027593862265348434,\n",
              "  -0.04489952325820923,\n",
              "  -0.13186948001384735,\n",
              "  0.027674969285726547,\n",
              "  0.00012546137440949678,\n",
              "  -0.0863247886300087,\n",
              "  0.07759274542331696,\n",
              "  0.0671803280711174,\n",
              "  0.00944465957581997,\n",
              "  -0.044386133551597595,\n",
              "  0.003998391330242157,\n",
              "  -0.0011632241075858474,\n",
              "  -0.01478781457990408,\n",
              "  0.003102256217971444,\n",
              "  -0.00833426509052515,\n",
              "  -0.05093568563461304,\n",
              "  0.10310415923595428,\n",
              "  -0.164327472448349,\n",
              "  -0.05344550311565399,\n",
              "  0.030625028535723686,\n",
              "  0.10296173393726349,\n",
              "  -0.04060475528240204,\n",
              "  0.025226302444934845,\n",
              "  -0.008608200587332249,\n",
              "  0.01022832840681076,\n",
              "  -0.02007106877863407,\n",
              "  -0.017246395349502563,\n",
              "  -0.0031408723443746567,\n",
              "  0.010965440422296524,\n",
              "  -0.0004650416085496545,\n",
              "  0.1253504902124405,\n",
              "  0.07790344208478928,\n",
              "  -0.007502386346459389,\n",
              "  -0.049789585173130035,\n",
              "  0.06594855338335037,\n",
              "  0.029734911397099495,\n",
              "  -0.009204906411468983,\n",
              "  0.01533439289778471,\n",
              "  -0.006461679469794035,\n",
              "  0.002746688202023506,\n",
              "  0.0007090047583915293,\n",
              "  -0.022287195548415184,\n",
              "  0.07711846381425858,\n",
              "  -0.01936129294335842,\n",
              "  0.03689638897776604,\n",
              "  0.1039223000407219,\n",
              "  0.037061676383018494,\n",
              "  -0.08666341006755829,\n",
              "  -0.01817575842142105,\n",
              "  -0.005875063594430685,\n",
              "  0.006972677074372768,\n",
              "  -0.024439431726932526,\n",
              "  0.015261316671967506,\n",
              "  0.05319192633032799,\n",
              "  0.015531864017248154,\n",
              "  -0.07178954780101776,\n",
              "  0.005859137512743473,\n",
              "  -0.08144553750753403,\n",
              "  0.03024504892528057,\n",
              "  -0.13386857509613037,\n",
              "  0.08936826884746552,\n",
              "  -0.009129791520535946,\n",
              "  0.08467649668455124,\n",
              "  0.011604027822613716,\n",
              "  -0.046746209263801575,\n",
              "  0.009623785503208637,\n",
              "  -0.01219873782247305,\n",
              "  0.06146737188100815,\n",
              "  -0.053787875920534134,\n",
              "  6.0685335483867675e-05,\n",
              "  0.046191565692424774,\n",
              "  0.006491404492408037,\n",
              "  0.006931229028850794,\n",
              "  -0.01916232332587242,\n",
              "  -0.03324596956372261,\n",
              "  -0.02963513508439064,\n",
              "  -0.04131831228733063,\n",
              "  0.043926529586315155,\n",
              "  0.00995566975325346,\n",
              "  -0.07658974081277847,\n",
              "  0.11076183617115021,\n",
              "  -0.061676688492298126,\n",
              "  -0.0014491189504042268,\n",
              "  -0.006293540820479393,\n",
              "  -0.03969135135412216,\n",
              "  -0.07352851331233978,\n",
              "  -0.036891255527734756,\n",
              "  0.040743518620729446,\n",
              "  0.044748518615961075,\n",
              "  -0.04744938015937805,\n",
              "  -5.7709520717708074e-08,\n",
              "  0.019909048452973366,\n",
              "  -0.046692248433828354,\n",
              "  0.037434086203575134,\n",
              "  -0.03196284919977188,\n",
              "  0.11824856698513031,\n",
              "  -0.01930806413292885,\n",
              "  -0.041673969477415085,\n",
              "  0.06990700215101242,\n",
              "  -0.027254663407802582,\n",
              "  0.05071217194199562,\n",
              "  0.033614691346883774,\n",
              "  -0.03411521017551422,\n",
              "  -0.01225573942065239,\n",
              "  0.05571526661515236,\n",
              "  0.06282475590705872,\n",
              "  0.07809958606958389,\n",
              "  0.03756345808506012,\n",
              "  -0.062037285417318344,\n",
              "  -0.007577132433652878,\n",
              "  0.02158881165087223,\n",
              "  0.057025451213121414,\n",
              "  -0.07005675137042999,\n",
              "  -0.03310862183570862,\n",
              "  -0.05440828576683998,\n",
              "  -0.0011363811790943146,\n",
              "  -0.03531757742166519,\n",
              "  -0.04922475293278694,\n",
              "  -0.039346903562545776,\n",
              "  0.007983569987118244,\n",
              "  0.042643215507268906,\n",
              "  0.021714871749281883,\n",
              "  -0.0060126096941530704,\n",
              "  0.024814758449792862,\n",
              "  0.04810256510972977,\n",
              "  0.053439315408468246,\n",
              "  -0.04770379886031151,\n",
              "  -0.00038017737097106874,\n",
              "  -0.11559400707483292,\n",
              "  -0.03672602400183678,\n",
              "  -0.008591951802372932,\n",
              "  0.03674641251564026,\n",
              "  0.07767920941114426,\n",
              "  0.009696169756352901,\n",
              "  0.003833745140582323,\n",
              "  -0.1144833192229271,\n",
              "  -0.04120960459113121,\n",
              "  -0.01795569248497486,\n",
              "  -0.0438995435833931,\n",
              "  0.026953861117362976,\n",
              "  0.047898948192596436,\n",
              "  -0.011902634985744953,\n",
              "  -0.02716204710304737,\n",
              "  0.05624467507004738,\n",
              "  -0.003662546630948782,\n",
              "  0.09074590355157852,\n",
              "  0.017356181517243385,\n",
              "  0.07640479505062103,\n",
              "  -0.03815674036741257,\n",
              "  -0.051781196147203445,\n",
              "  0.11135200411081314,\n",
              "  0.033098261803388596,\n",
              "  -0.004181948956102133,\n",
              "  -0.1286875158548355,\n",
              "  -0.06361716240644455]]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "word_vectors = getado[\"embeddings\"]\n",
        "word_list = getado[\"documents\"]\n",
        "word_vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bebef744",
      "metadata": {
        "papermill": {
          "duration": 0.020311,
          "end_time": "2024-02-21T15:59:55.063094",
          "exception": false,
          "start_time": "2024-02-21T15:59:55.042783",
          "status": "completed"
        },
        "tags": [],
        "id": "bebef744"
      },
      "source": [
        "Once we have our information inside the Database we can query It, and ask for data that matches our needs. The search is done inside the content of the document, and it dosn't look for the exact word, or phrase. The results will be based on the similarity between the search terms and the content of documents.\n",
        "\n",
        "The metadata is not used in the search, but they can be utilized for filtering or refining the results after the initial search.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b453d6c",
      "metadata": {
        "papermill": {
          "duration": 0.020024,
          "end_time": "2024-02-21T15:59:55.103621",
          "exception": false,
          "start_time": "2024-02-21T15:59:55.083597",
          "status": "completed"
        },
        "tags": [],
        "id": "4b453d6c"
      },
      "source": [
        "## Loading the model and creating the prompt\n",
        "\n",
        "TRANSFORMERS!!\n",
        "Time to use the library **transformers**, the most famous library from [hugging face](https://huggingface.co/) for working with language models.\n",
        "\n",
        "We are importing:\n",
        "* **Autotokenizer**: It is a utility class for tokenizing text inputs that are compatible with various pre-trained language models.\n",
        "* **AutoModelForCasualLLM**: it provides an interface to pre-trained language models specifically designed for language generation tasks using causal language modeling (e.g., GPT models), or the model used in this notebook ***databricks/dolly-v2-3b***.\n",
        "* **pipeline**: provides a simple interface for performing various natural language processing (NLP) tasks, such as text generation (our case) or text classification.\n",
        "\n",
        "The model selected is [dolly-v2-3b](https://huggingface.co/databricks/dolly-v2-3b), the smallest Dolly model. It have 3billion paramaters, more than enough for our sample, and works much better than GPT2.\n",
        "\n",
        "Please, feel free to test [different Models](https://huggingface.co/models?pipeline_tag=text-generation&sort=trending), you need to search for NLP models trained for text-generation. My recomendation is choose \"small\" models, or we will run out of memory in kaggle.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "92a68bf6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T15:59:55.146747Z",
          "iopub.status.busy": "2024-02-21T15:59:55.146229Z",
          "iopub.status.idle": "2024-02-21T16:00:50.959024Z",
          "shell.execute_reply": "2024-02-21T16:00:50.957445Z"
        },
        "papermill": {
          "duration": 55.839281,
          "end_time": "2024-02-21T16:00:50.963197",
          "exception": false,
          "start_time": "2024-02-21T15:59:55.123916",
          "status": "completed"
        },
        "tags": [],
        "id": "92a68bf6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "model_id = \"databricks/dolly-v2-3b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "lm_model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c03c93f7",
      "metadata": {
        "papermill": {
          "duration": 0.024466,
          "end_time": "2024-02-21T16:00:51.011156",
          "exception": false,
          "start_time": "2024-02-21T16:00:50.98669",
          "status": "completed"
        },
        "tags": [],
        "id": "c03c93f7"
      },
      "source": [
        "The next step is to initialize the pipeline using the objects created above.\n",
        "\n",
        "The model's response is limited to 256 tokens, for this project I'm not interested in a longer response, but it can easily be extended to whatever length you want.\n",
        "\n",
        "Setting ***device_map*** to ***auto*** we are instructing the model to automaticaly select the most appropiate device: CPU or GPU for processing the text generation.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "7660416b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T16:00:51.063678Z",
          "iopub.status.busy": "2024-02-21T16:00:51.062032Z",
          "iopub.status.idle": "2024-02-21T16:00:51.077146Z",
          "shell.execute_reply": "2024-02-21T16:00:51.075582Z"
        },
        "papermill": {
          "duration": 0.043207,
          "end_time": "2024-02-21T16:00:51.080338",
          "exception": false,
          "start_time": "2024-02-21T16:00:51.037131",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7660416b",
        "outputId": "2e2968f3-e150-4500-f4b4-d67eb6f103ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=lm_model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=256,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4141db50",
      "metadata": {
        "papermill": {
          "duration": 0.022571,
          "end_time": "2024-02-21T16:00:51.125582",
          "exception": false,
          "start_time": "2024-02-21T16:00:51.103011",
          "status": "completed"
        },
        "tags": [],
        "id": "4141db50"
      },
      "source": [
        "## Creating the extended prompt\n",
        "To create the prompt we use the result from query the Vector Database  and the sentence introduced by the user.\n",
        "\n",
        "The prompt have two parts, the **relevant context** that is the information recovered from the database and the **user's question**.\n",
        "\n",
        "We only need to join the two parts together to create the prompt that we are going to send to the model.\n",
        "\n",
        "You can limit the lenght of the context passed to the model, because we can get some Memory problems with one of the datasets that contains a realy large text in the document part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "574efc79",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T16:00:51.177367Z",
          "iopub.status.busy": "2024-02-21T16:00:51.176567Z",
          "iopub.status.idle": "2024-02-21T16:00:51.184306Z",
          "shell.execute_reply": "2024-02-21T16:00:51.18338Z"
        },
        "papermill": {
          "duration": 0.03515,
          "end_time": "2024-02-21T16:00:51.186906",
          "exception": false,
          "start_time": "2024-02-21T16:00:51.151756",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "574efc79",
        "outputId": "7784469a-22e6-4c26-e81d-44ed91348e41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Relevant context: #[\\'Picture two teams squaring off on a football field. The players can cooperate to achieve an objective, and compete against other players with conflicting interests. That’s how the game works.\\', \\'\\', \\'Creating artificial intelligence agents that can learn to compete and cooperate as effectively as humans remains a thorny problem. A key challenge is enabling AI agents to anticipate future behaviors of other agents when they are all learning simultaneously.\\', \\'\\', \\'Because of the complexity of this problem, current approaches tend to be myopic; the agents can only guess the next few moves of their teammates or competitors, which leads to poor performance in the long run.\\', \\'\\', \\'Researchers from MIT, the MIT-IBM Watson AI Lab, and elsewhere have developed a new approach that gives AI agents a farsighted perspective. Their machine-learning framework enables cooperative or competitive AI agents to consider what other agents will do as time approaches infinity, not just over a few next steps. The agents then adapt their behaviors accordingly to influence other agents’ future behaviors and arrive at an optimal, long-term solution.\\', \\'\\', \\'This framework could be used by a group of autonomous drones working together to find a lost hiker in a thick forest, or by self-driving cars that strive to keep passengers safe by anticipating future moves of other vehicles driving on a busy highway.\\', \\'\\', \\'“When AI agents are cooperating or competing, what matters most is when their behaviors converge at some point in the future. There are a lot of transient behaviors along the way that don’t matter very much in the long run. Reaching this converged behavior is what we really care about, and we now have a mathematical way to enable that,” says Dong-Ki Kim, a graduate student in the MIT Laboratory for Information and Decision Systems (LIDS) and lead author of a paper describing this framework.\\', \\'\\', \\'The senior author is Jonathan P. How, the Richard C. Maclaurin Professor of Aeronautics and Astronautics and a member of the MIT-IBM Watson AI Lab. Co-authors include others at the MIT-IBM Watson AI Lab, IBM Research, Mila-Quebec Artificial Intelligence Institute, and Oxford University. The research will be presented at the Conference on Neural Information Processing Systems.\\', \\'\\'] #[\\'In a packed room in MIT’s Stata Center, hundreds of digital robots collide across a giant screen projected at the front of the room. A crowd of students in the audience gasps and cheers as the battle’s outcome hangs in the balance. In an upper corner of the screen, the people who have programmed the robot armies’ strategies narrate the action in real time.\\', \\'This isn’t the latest e-sports event, it’s MIT’s long-running Battlecode competition. Open to student teams around the world, Battlecode tasks participants with writing the code to program entire armies — not just individual bots — before they duke it out. The resulting dramatic, often-unexpected outcomes are decided based on whose programming strategy aligns best with the parameters of the game and the circumstances of the battle.\\', \\'The unique competition pushes teams to spend hours coding and refining their armies in a quest for the perfectly crafted game plan. Since 2007, the competition has involved high school and college students from around the world, upping the intellectual ante as people with diverse backgrounds tackle the open-ended challenge.\\'] #[\\'Government should not “abdicate” its responsibilities and leave the future path of artificial intelligence solely to Big Tech, Aleksander Mądry, the Cadence Design Systems Professor of Computing at MIT and director of the MIT Center for Deployable Machine Learning, told a Congressional panel on Wednesday.\\', \\'Rather, Mądry said, government should be asking questions about the purpose and explainability of the algorithms corporations are using, as a precursor to regulation, which he described as “an important tool” in ensuring that AI is consistent with society’s goals. If the government doesn’t start asking questions, then “I am extremely worried” about the future of AI, Mądry said in response to a question from Rep. Gerald Connolly.\\', \\'Mądry, a leading expert on explainability and AI, was testifying at a hearing titled “Advances in AI: Are We Ready for a Tech Revolution?” before the House Subcommittee on Cybersecurity, Information Technology, and Government Innovation, a panel of the House Committee on Government Reform and Oversight. The other witnesses at the hearing were former Google CEO Eric Schmidt, IBM Vice President Scott Crowder, and Center for AI and Digital Policy Senior Research Director Merve Hickok.\\', \\'In her opening remarks, Subcommittee Chair Rep. Nancy Mace cited the book “The Age of AI: And Our Human Future” by Schmidt, Henry Kissinger, and Dan Huttenlocher, the dean of the MIT Schwarzman College of Computing. She also called attention to a March 3 op-ed in The Wall Street Journal by the three authors that summarized the book while discussing ChatGPT. Mace said her formal opening remarks had been entirely written by ChatGPT.\\', \\'In his prepared remarks, Mądry raised three overarching points. First, he noted that AI is “no longer a matter of science fiction” or confined to research labs. It is out in the world, where it can bring enormous benefits but also poses risks.\\', \\'Second, he said AI exposes us to “interactions that go against our intuition.” He said because AI tools like ChatGPT mimic human communication, people are too likely to unquestioningly believe what such large language models produce. In the worst case, Mądry warned, human analytical skills will atrophy. He also said it would be a mistake to regulate AI as if it were human — for example, by asking AI to explain its reasoning and assuming that the resulting answers are credible.\\', \\'Finally, he said too little attention has been paid to problems that will result from the nature of the AI “supply chain” — the way AI systems are built on top of each other. At the base are general systems like ChatGPT, which can be developed by only a few companies because they are so expensive and complex to build. Layered on top of such systems are many AI systems designed to handle a particular task, like figuring out whom a company should hire.\\', \\'Mądry said this layering raised several “policy-relevant” concerns. First, the entire system of AI is subject to whatever vulnerabilities or biases are in the large system at its base, and is dependent on the work of a few, large companies. Second, the interaction of AI systems is not well-understood from a technical standpoint, making the results of AI even more difficult to predict or explain, and making the tools difficult to “audit.” Finally, the mix of AI tools makes it difficult to know whom to hold responsible when a problem results — who should be legally liable and who should address the concern.\\', \\'In the written material submitted to the subcommittee, Mądry concluded, “AI technology is not particularly well-suited for deployment through complex supply chains,” even though that is exactly how it is being deployed.\\', \\'Mądry ended his testimony by calling on Congress to probe AI issues and to be prepared to act. “We are at an inflection point in terms of what future AI will bring. Seizing this opportunity means discussing the role of AI, what exactly we want it to do for us, and how to ensure it benefits us all. This will be a difficult conversation but we do need to have it, and have it now,” he told the subcommittee.\\', \\'The testimony of all the hearing witnesses and a video of the hearing, which lasted about two hours, is available online.\\'] #[\\'The rapid advance of artificial intelligence has generated a lot of buzz, with some predicting it will lead to an idyllic utopia and others warning it will bring the end of humanity. But speculation about where AI technology is going, while important, can also drown out important conversations about how we should be handling the AI technologies available today.\\', \\'One such technology is generative AI, which can create content including text, images, audio, and video. Popular generative AIs like the chatbot ChatGPT generate conversational text based on training data taken from the internet.\\', \\'Today a group of 14 researchers from a number of organizations including MIT published a commentary article in Science that helps set the stage for discussions about generative AI’s immediate impact on creative work and society more broadly. The paper’s MIT-affiliated co-authors include Media Lab postdoc Ziv Epstein SM ’19, PhD ’23; Matt Groh SM ’19, PhD ’23; PhD students Rob Mahari ’17 and Hope Schroeder; and Professor Alex \"Sandy\" Pentland.\\', \\'MIT News spoke with Epstein, the lead author of the paper.\\', \\'Q: Why did you write this paper?\\', \\'A: Generative AI tools are doing things that even a few years ago we never thought would be possible. This raises a lot of fundamental questions about the creative process and the human’s role in creative production. Are we going to get automated out of jobs? How are we going to preserve the human aspect of creativity with all of these new technologies?\\', \\'The complexity of black-box AI systems can make it hard for researchers and the broader public to understand what’s happening under the hood, and what the impacts of these tools on society will be. Many discussions about AI anthropomorphize the technology, implicitly suggesting these systems exhibit human-like intent, agency, or self-awareness. Even the term “artificial intelligence” reinforces these beliefs: ChatGPT uses first-person pronouns, and we say AIs “hallucinate.” These agentic roles we give AIs can undermine the credit to creators whose labor underlies the system’s outputs, and can deflect responsibility from the developers and decision makers when the systems cause harm.\\', \\'We’re trying to build coalitions across academia and beyond to help think about the interdisciplinary connections and research areas necessary to grapple with the immediate dangers to humans coming from the deployment of these tools, such as disinformation, job displacement, and changes to legal structures and culture.\\', \\'Q: What do you see as the gaps in research around generative AI and art today?\\', \\'A: The way we talk about AI is broken in many ways. We need to understand how perceptions of the generative process affect attitudes toward outputs and authors, and also design the interfaces and systems in a way that is really transparent about the generative process and avoids some of these misleading interpretations. How do we talk about AI and how do these narratives cut along lines of power? As we outline in the article, there are these themes around AI’s impact that are important to consider: aesthetics and culture; legal aspects of ownership and credit; labor; and the impacts to the media ecosystem. For each of those we highlight the big open questions.\\', \\'With aesthetics and culture, we’re considering how past art technologies can inform how we think about AI. For example, when photography was invented, some painters said it was “the end of art.” But instead it ended up being its own medium and eventually liberated painting from realism, giving rise to Impressionism and the modern art movement. We’re saying generative AI is a medium with its own affordances. The nature of art will evolve with that. How will artists and creators express their intent and style through this new medium?\\', \\'Issues around ownership and credit are tricky because we need copyright law that benefits creators, users, and society at large. Today’s copyright laws might not adequately apportion rights to artists when these systems are training on their styles. When it comes to training data, what does it mean to copy? That’s a legal question, but also a technical question. We’re trying to understand if these systems are copying, and when.\\', \\'For labor economics and creative work, the idea is these generative AI systems can accelerate the creative process in many ways, but they can also remove the ideation process that starts with a blank slate. Sometimes, there’s actually good that comes from starting with a blank page. We don’t know how it’s going to influence creativity, and we need a better understanding of how AI will affect the different stages of the creative process. We need to think carefully about how we use these tools to complement people’s work instead of replacing it.\\', \\'In terms of generative AI’s effect on the media ecosystem, with the ability to produce synthetic media at scale, the risk of AI-generated misinformation must be considered. We need to safeguard the media ecosystem against the possibility of massive fraud on one hand, and people losing trust in real media on the other.\\', \\'Q: How do you hope this paper is received — and by whom?\\', \\'A: The conversation about AI has been very fragmented and frustrating. Because the technologies are moving so fast, it’s been hard to think deeply about these ideas. To ensure the beneficial use of these technologies, we need to build shared language and start to understand where to focus our attention. We’re hoping this paper can be a step in that direction. We’re trying to start a conversation that can help us build a roadmap toward understanding this fast-moving situation.\\', \\'Artists many times are at the vanguard of new technologies. They’re playing with the technology long before there are commercial applications. They’re exploring how it works, and they’re wrestling with the ethics of it. AI art has been going on for over a decade, and for as long these artists have been grappling with the questions we now face as a society. I think it is critical to uplift the voices of the artists and other creative laborers whose jobs will be impacted by these tools. Art is how we express our humanity. It’s a core human, emotional part of life. In that way we believe it’s at the center of broader questions about AI’s impact on society, and hopefully we can ground that discussion with this.\\'] #[\\'There has been a remarkable surge in the use of algorithms and artificial intelligence to address a wide range of problems and challenges. While their adoption, particularly with the rise of AI, is reshaping nearly every industry sector, discipline, and area of research, such innovations often expose unexpected consequences that involve new norms, new expectations, and new rules and laws.\\', \\'To facilitate deeper understanding, the Social and Ethical Responsibilities of Computing (SERC), a cross-cutting initiative in the MIT Schwarzman College of Computing, recently brought together social scientists and humanists with computer scientists, engineers, and other computing faculty for an exploration of the ways in which the broad applicability of algorithms and AI has presented both opportunities and challenges in many aspects of society.\\', \\'“The very nature of our reality is changing. AI has the ability to do things that until recently were solely the realm of human intelligence — things that can challenge our understanding of what it means to be human,” remarked Daniel Huttenlocher, dean of the MIT Schwarzman College of Computing, in his opening address at the inaugural SERC Symposium. “This poses philosophical, conceptual, and practical questions on a scale not experienced since the start of the Enlightenment. In the face of such profound change, we need new conceptual maps for navigating the change.”\\', \\'The symposium offered a glimpse into the vision and activities of SERC in both research and education. “We believe our responsibility with SERC is to educate and equip our students and enable our faculty to contribute to responsible technology development and deployment,” said Georgia Perakis, the William F. Pounds Professor of Management in the MIT Sloan School of Management, co-associate dean of SERC, and the lead organizer of the symposium. “We’re drawing from the many strengths and diversity of disciplines across MIT and beyond and bringing them together to gain multiple viewpoints.”\\', \\'Through a succession of panels and sessions, the symposium delved into a variety of topics related to the societal and ethical dimensions of computing. In addition, 37 undergraduate and graduate students from a range of majors, including urban studies and planning, political science, mathematics, biology, electrical engineering and computer science, and brain and cognitive sciences, participated in a poster session to exhibit their research in this space, covering such topics as quantum ethics, AI collusion in storage markets, computing waste, and empowering users on social platforms for better content credibility.\\', \\'Showcasing a diversity of work\\', \\'In three sessions devoted to themes of beneficent and fair computing, equitable and personalized health, and algorithms and humans, the SERC Symposium showcased work by 12 faculty members across these domains.\\', \\'One such project from a multidisciplinary team of archaeologists, architects, digital artists, and computational social scientists aimed to preserve endangered heritage sites in Afghanistan with digital twins. The project team produced highly detailed interrogable 3D models of the heritage sites, in addition to extended reality and virtual reality experiences, as learning resources for audiences that cannot access these sites.\\', \\'In a project for the United Network for Organ Sharing, researchers showed how they used applied analytics to optimize various facets of an organ allocation system in the United States that is currently undergoing a major overhaul in order to make it more efficient, equitable, and inclusive for different racial, age, and gender groups, among others.\\', \\'Another talk discussed an area that has not yet received adequate public attention: the broader implications for equity that biased sensor data holds for the next generation of models in computing and health care.\\', \\'A talk on bias in algorithms considered both human bias and algorithmic bias, and the potential for improving results by taking into account differences in the nature of the two kinds of bias.\\', \\'Other highlighted research included the interaction between online platforms and human psychology; a study on whether decision-makers make systemic prediction mistakes on the available information; and an illustration of how advanced analytics and computation can be leveraged to inform supply chain management, operations, and regulatory work in the food and pharmaceutical industries.\\', \\'Improving the algorithms of tomorrow\\', \\'“Algorithms are, without question, impacting every aspect of our lives,” said Asu Ozdaglar, deputy dean of academics for the MIT Schwarzman College of Computing and head of the Department of Electrical Engineering and Computer Science, in kicking off a panel she moderated on the implications of data and algorithms.\\', \\'“Whether it’s in the context of social media, online commerce, automated tasks, and now a much wider range of creative interactions with the advent of generative AI tools and large language models, there’s little doubt that much more is to come,” Ozdaglar said. “While the promise is evident to all of us, there’s a lot to be concerned as well. This is very much time for imaginative thinking and careful deliberation to improve the algorithms of tomorrow.”\\', \\'Turning to the panel, Ozdaglar asked experts from computing, social science, and data science for insights on how to understand what is to come and shape it to enrich outcomes for the majority of humanity.\\', \\'Sarah Williams, associate professor of technology and urban planning at MIT, emphasized the critical importance of comprehending the process of how datasets are assembled, as data are the foundation for all models. She also stressed the need for research to address the potential implication of biases in algorithms that often find their way in through their creators and the data used in their development. “It’s up to us to think about our own ethical solutions to these problems,” she said. “Just as it’s important to progress with the technology, we need to start the field of looking at these questions of what biases are in the algorithms? What biases are in the data, or in that data’s journey?”\\', \\'Shifting focus to generative models and whether the development and use of these technologies should be regulated, the panelists — which also included MIT’s Srini Devadas, professor of electrical engineering and computer science, John Horton, professor of information technology, and Simon Johnson, professor of entrepreneurship — all concurred that regulating open-source algorithms, which are publicly accessible, would be difficult given that regulators are still catching up and struggling to even set guardrails for technology that is now 20 years old.\\', \"Returning to the question of how to effectively regulate the use of these technologies, Johnson proposed a progressive corporate tax system as a potential solution. He recommends basing companies\\' tax payments on their profits, especially for large corporations whose massive earnings go largely untaxed due to offshore banking. By doing so, Johnson said that this approach can serve as a regulatory mechanism that discourages companies from trying to “own the entire world” by imposing disincentives.\", \\'The role of ethics in computing education\\', \\'As computing continues to advance with no signs of slowing down, it is critical to educate students to be intentional in the social impact of the technologies they will be developing and deploying into the world. But can one actually be taught such things? If so, how?\\', \\'Caspar Hare, professor of philosophy at MIT and co-associate dean of SERC, posed this looming question to faculty on a panel he moderated on the role of ethics in computing education. All experienced in teaching ethics and thinking about the social implications of computing, each panelist shared their perspective and approach.\\', \\'A strong advocate for the importance of learning from history, Eden Medina, associate professor of science, technology, and society at MIT, said that “often the way we frame computing is that everything is new. One of the things that I do in my teaching is look at how people have confronted these issues in the past and try to draw from them as a way to think about possible ways forward.” Medina regularly uses case studies in her classes and referred to a paper written by Yale University science historian Joanna Radin on the Pima Indian Diabetes Dataset that raised ethical issues on the history of that particular collection of data that many don’t consider as an example of how decisions around technology and data can grow out of very specific contexts.\\', \\'Milo Phillips-Brown, associate professor of philosophy at Oxford University, talked about the Ethical Computing Protocol that he co-created while he was a SERC postdoc at MIT. The protocol, a four-step approach to building technology responsibly, is designed to train computer science students to think in a better and more accurate way about the social implications of technology by breaking the process down into more manageable steps. “The basic approach that we take very much draws on the fields of value-sensitive design, responsible research and innovation, participatory design as guiding insights, and then is also fundamentally interdisciplinary,” he said.\\', \\'Fields such as biomedicine and law have an ethics ecosystem that distributes the function of ethical reasoning in these areas. Oversight and regulation are provided to guide front-line stakeholders and decision-makers when issues arise, as are training programs and access to interdisciplinary expertise that they can draw from. “In this space, we have none of that,” said John Basl, associate professor of philosophy at Northeastern University. “For current generations of computer scientists and other decision-makers, we’re actually making them do the ethical reasoning on their own.” Basl commented further that teaching core ethical reasoning skills across the curriculum, not just in philosophy classes, is essential, and that the goal shouldn’t be for every computer scientist be a professional ethicist, but for them to know enough of the landscape to be able to ask the right questions and seek out the relevant expertise and resources that exists.\\', \\'After the final session, interdisciplinary groups of faculty, students, and researchers engaged in animated discussions related to the issues covered throughout the day during a reception that marked the conclusion of the symposium.\\'] #[\\'In the vast, expansive skies where birds once ruled supreme, a new crop of aviators is taking flight. These pioneers of the air are not living creatures, but rather a product of deliberate innovation: drones. But these aren’t your typical flying bots, humming around like mechanical bees. Rather, they’re avian-inspired marvels that soar through the sky, guided by liquid neural networks to navigate ever-changing and unseen environments with precision and ease.\\', \\'Inspired by the adaptable nature of organic brains, researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) have introduced a method for robust flight navigation agents to master vision-based fly-to-target tasks in intricate, unfamiliar environments. The liquid neural networks, which can continuously adapt to new data inputs, showed prowess in making reliable decisions in unknown domains like forests, urban landscapes, and environments with added noise, rotation, and occlusion. These adaptable models, which outperformed many state-of-the-art counterparts in navigation tasks, could enable potential real-world drone applications like search and rescue, delivery, and wildlife monitoring.\\', \"The researchers\\' recent study, published today in Science Robotics, details how this new breed of agents can adapt to significant distribution shifts, a long-standing challenge in the field. The team’s new class of machine-learning algorithms, however, captures the causal structure of tasks from high-dimensional, unstructured data, such as pixel inputs from a drone-mounted camera. These networks can then extract crucial aspects of a task (i.e., understand the task at hand) and ignore irrelevant features, allowing acquired navigation skills to transfer targets seamlessly to new environments.\"] #[\"It’s a dilemma as old as time. Friday night has rolled around, and you’re trying to pick a restaurant for dinner. Should you visit your most beloved watering hole or try a new establishment, in the hopes of discovering something superior? Potentially, but that curiosity comes with a risk: If you explore the new option, the food could be worse. On the flip side, if you stick with what you know works well, you won\\'t grow out of your narrow pathway.\", \\'Curiosity drives artificial intelligence to explore the world, now in boundless use cases — autonomous navigation, robotic decision-making, optimizing health outcomes, and more. Machines, in some cases, use “reinforcement learning” to accomplish a goal, where an AI agent iteratively learns from being rewarded for good behavior and punished for bad. Just like the dilemma faced by humans in selecting a restaurant, these agents also struggle with balancing the time spent discovering better actions (exploration) and the time spent taking actions that led to high rewards in the past (exploitation). Too much curiosity can distract the agent from making good decisions, while too little means the agent will never discover good decisions.\\', \"In the pursuit of making AI agents with just the right dose of curiosity, researchers from MIT’s Improbable AI Laboratory and Computer Science and Artificial Intelligence Laboratory (CSAIL) created an algorithm that overcomes the problem of AI being too “curious” and getting distracted by a given task. Their algorithm automatically increases curiosity when it\\'s needed, and suppresses it if the agent gets enough supervision from the environment to know what to do.\", \\'When tested on over 60 video games, the algorithm was able to succeed at both hard and easy exploration tasks, where previous algorithms have only been able to tackle only a hard or easy domain alone. With this method, AI agents use fewer data for learning decision-making rules that maximize incentives.\\', \"“If you master the exploration-exploitation trade-off well, you can learn the right decision-making rules faster — and anything less will require lots of data, which could mean suboptimal medical treatments, lesser profits for websites, and robots that don\\'t learn to do the right thing,” says Pulkit Agrawal, an assistant professor of electrical engineering and computer science (EECS) at MIT, director of the Improbable AI Lab, and CSAIL affiliate who supervised the research. “Imagine a website trying to figure out the design or layout of its content that will maximize sales. If one doesn’t perform exploration-exploitation well, converging to the right website design or the right website layout will take a long time, which means profit loss. Or in a health care setting, like with Covid-19, there may be a sequence of decisions that need to be made to treat a patient, and if you want to use decision-making algorithms, they need to learn quickly and efficiently — you don\\'t want a suboptimal solution when treating a large number of patients. We hope that this work will apply to real-world problems of that nature.”\", \\'It’s hard to encompass the nuances of curiosity’s psychological underpinnings; the underlying neural correlates of challenge-seeking behavior are a poorly understood phenomenon. Attempts to categorize the behavior have spanned studies that dived deeply into studying our impulses, deprivation sensitivities, and social and stress tolerances.\\', \\'With reinforcement learning, this process is “pruned” emotionally and stripped down to the bare bones, but it’s complicated on the technical side. Essentially, the agent should only be curious when there’s not enough supervision available to try out different things, and if there is supervision, it must adjust curiosity and lower it.\\', \\'Since a large subset of gaming is little agents running around fantastical environments looking for rewards and performing a long sequence of actions to achieve some goal, it seemed like the logical test bed for the researchers’ algorithm. In experiments, researchers divided games like “Mario Kart” and “Montezuma’s Revenge” into two different buckets: one where supervision was sparse, meaning the agent had less guidance, which were considered “hard” exploration games, and a second where supervision was more dense, or the “easy” exploration games.\\', \\'Suppose in “Mario Kart,” for example, you only remove all rewards so you don’t know when an enemy eliminates you. You’re not given any reward when you collect a coin or jump over pipes. The agent is only told in the end how well it did. This would be a case of sparse supervision. Algorithms that incentivize curiosity do really well in this scenario.\\', \\'But now, suppose the agent is provided dense supervision — a reward for jumping over pipes, collecting coins, and eliminating enemies. Here, an algorithm without curiosity performs really well because it gets rewarded often. But if you instead take the algorithm that also uses curiosity, it learns slowly. This is because the curious agent might attempt to run fast in different ways, dance around, go to every part of the game screen — things that are interesting, but do not help the agent succeed at the game. The team’s algorithm, however, consistently performed well, irrespective of what environment it was in.\\', \\'Future work might involve circling back to the exploration that’s delighted and plagued psychologists for years: an appropriate metric for curiosity — no one really knows the right way to mathematically define curiosity.\\', \\'“Getting consistent good performance on a novel problem is extremely challenging — so by improving exploration algorithms, we can save your effort on tuning an algorithm for your problems of interest, says Zhang-Wei Hong, an EECS PhD student, CSAIL affiliate, and co-lead author along with Eric Chen\\\\xa0’20, MEng\\\\xa0’21 on a new paper about the work. “We need curiosity to solve extremely challenging problems, but on some problems it can hurt performance. We propose an algorithm that removes the burden of tuning the balance of exploration and exploitation. Previously what took, for instance, a week to successfully solve the problem, with this new algorithm, we can get satisfactory results in a few hours.”\\', \\'“One of the greatest challenges for current AI and cognitive science is how to balance exploration and exploitation — the search for information versus the search for reward. Children do this seamlessly, but it is challenging computationally,” notes Alison Gopnik, professor of psychology and affiliate professor of philosophy at the University of California at Berkeley, who was not involved with the project. “This paper uses impressive new techniques to accomplish this automatically, designing an agent that can systematically balance curiosity about the world and the desire for reward, [thus taking] another step towards making AI agents (almost) as smart as children.”\\', \\'“Intrinsic rewards like curiosity are fundamental to guiding agents to discover useful diverse behaviors, but this shouldn’t come at the cost of doing well at the given task. This is an important problem in AI, and the paper provides a way to balance that trade-off,” adds Deepak Pathak, an assistant professor at Carnegie Mellon University, who was also not involved in the work.\\\\xa0“It would be interesting to see how such methods scale beyond games to real-world robotic agents.”\\', \\'Chen, Hong, and Agrawal wrote the paper alongside Joni Pajarinen, assistant professor at Aalto University and research leader at the Intelligent Autonomous Systems Group at TU Darmstadt. The research was supported, in part, by the MIT-IBM Watson AI Lab, DARPA Machine Common Sense Program, the Army Research Office by the United States Air Force Research Laboratory, and the United States Air Force Artificial Intelligence Accelerator. The paper will be presented at Neural Information and Processing Systems (NeurIPS) 2022.\\'] #[\"If you\\'ve ever played soccer with a robot, it\\'s a familiar feeling. Sun glistens down on your face as the smell of grass permeates the air. You look around. A four-legged robot is hustling toward you, dribbling with determination.\", \\'While the bot doesn’t display a Lionel Messi-like level of ability, it\\\\\\'s an impressive in-the-wild dribbling system nonetheless. Researchers from MIT\\\\\\'s Improbable Artificial Intelligence Lab, part of the Computer Science and Artificial Intelligence Laboratory (CSAIL), have developed a legged robotic system that can dribble a soccer ball under the same conditions as humans. The bot used a mixture of onboard sensing and computing to traverse different natural terrains such as sand, gravel, mud, and snow, and adapt to their varied impact on the ball’s motion. Like every committed athlete, \"DribbleBot\" could get up and recover the ball after falling.\\', \\'Programming robots to play soccer has been an active research area for some time. However, the team wanted to automatically learn how to actuate the legs during dribbling, to enable the discovery of hard-to-script skills for responding to diverse terrains like snow, gravel, sand, grass, and pavement. Enter, simulation.\\', \"A robot, ball, and terrain are inside the simulation\\\\xa0— a digital twin of the natural world. You can load in the bot and other assets and set physics parameters, and then it handles the forward simulation of the dynamics from there. Four thousand versions of the robot are simulated in parallel in real time, enabling data collection 4,000 times faster than using just one robot. That\\'s a lot of data.\"] #[\\'The emergence of generative artificial intelligence has ignited a deep philosophical exploration into the nature of consciousness, creativity, and authorship. As we bear witness to new advances in the field, it’s increasingly apparent that these synthetic agents possess a remarkable capacity to create, iterate, and challenge our traditional notions of intelligence. But what does it really mean for an AI system to be “generative,” with newfound blurred boundaries of creative expression between humans and machines?\\', \"For those who feel as if “generative artificial intelligence”\\\\xa0— a type of AI that can cook up new and original data or content similar to what it\\'s been trained on — cascaded into existence like an overnight sensation, while indeed the new capabilities have surprised many, the underlying technology has been in the making for some time.\", \\'But understanding true capacity can be as indistinct as some of the generative content these models produce. To that end, researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) convened in discussions around the capabilities and limitations of generative AI, as well as its potential impacts on society and industries, with regard to language, images, and code.\\', \\'There are various models of generative AI, each with their own unique approaches and techniques. These include generative adversarial networks (GANs), variational autoencoders (VAEs), and diffusion models, which have all shown off exceptional power in various industries and fields, from art to music and medicine. With that has also come a slew of ethical and social conundrums, such as the potential for generating fake news, deepfakes, and misinformation. Making these considerations is critical, the researchers say, to continue studying the capabilities and limitations of generative AI and ensure ethical use and responsibility.\\', \\'During opening remarks, to illustrate visual prowess of these models, MIT professor of electrical engineering and computer science (EECS) and CSAIL Director Daniela Rus pulled out a special gift her students recently bestowed upon her: a collage of AI portraits ripe with smiling shots of Rus, running a spectrum of mirror-like reflections. Yet, there was no commissioned artist in sight.\\', \\'The machine was to thank.\\', \\'Generative models learn to make imagery by downloading many photos from the internet and trying to make the output image look like the sample training data. There are many ways to train a neural network generator, and diffusion models are just one popular way. These models, explained by MIT associate professor of EECS and CSAIL principal investigator Phillip Isola, map from random noise to imagery. Using a process called diffusion, the model will convert structured objects like images into random noise, and the process is inverted by training a neural net to remove noise step by step until that noiseless image is obtained. If you’ve ever tried a hand at using DALL-E 2, where a sentence and random noise are input, and the noise congeals into images, you’ve used a diffusion model.\\'] #[\\'Sketch a doodle of a drum or a saxophone to conjure a multi-instrumental composition. Look into a webcam, speak, and watch your mouth go bouncing across the screen — the input for a series of charmingly clunky chain reactions.\\', \\'This is what visitors to the MIT Lewis Music Library encounter when they interact with two new digital installations, “Doodle Tunes” and “Sounds from the Mouth,” created by 2022-23 Center for Art and Technology (CAST) Visiting Artist Andreas Refsgaard in collaboration with Music Technology and Digital Media Librarian Caleb Hall. The residency was initiated by Avery Boddie, Lewis Music Library department head, who recognized Refsgaard’s flair for revealing the playfulness of emerging technologies. The intricacies of coding and machine learning can seem daunting to newcomers, but Refsgaard’s practice as a creative coder, interaction designer, and educator seeks to open the field to all. Encompassing workshops, an artist talk, class visits, and an exhibition, the residency was infused with his unique sense of humor — a combination of lively eccentricity and easygoing relatability.\\']\\n\\n The user\\'s question: What research has been done in MIT regarding AI agents?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "question = \"What research has been done in MIT regarding AI agents?\"\n",
        "context = \" \".join([f\"#{str(i)}\" for i in results[\"documents\"][0]])\n",
        "#context = context[0:5120]\n",
        "prompt_template = f\"Relevant context: {context}\\n\\n The user's question: {question}\"\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5977f60c",
      "metadata": {
        "papermill": {
          "duration": 0.022946,
          "end_time": "2024-02-21T16:00:51.232628",
          "exception": false,
          "start_time": "2024-02-21T16:00:51.209682",
          "status": "completed"
        },
        "tags": [],
        "id": "5977f60c"
      },
      "source": [
        "Now all that remains is to send the prompt to the model and wait for its response!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b04b71",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T16:00:51.284945Z",
          "iopub.status.busy": "2024-02-21T16:00:51.283942Z",
          "iopub.status.idle": "2024-02-21T16:01:18.932726Z",
          "shell.execute_reply": "2024-02-21T16:01:18.929859Z"
        },
        "papermill": {
          "duration": 27.680172,
          "end_time": "2024-02-21T16:01:18.936235",
          "exception": false,
          "start_time": "2024-02-21T16:00:51.256063",
          "status": "completed"
        },
        "tags": [],
        "id": "44b04b71"
      },
      "outputs": [],
      "source": [
        "lm_response = pipe(prompt_template)\n",
        "print(lm_response[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab2388a5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-12T22:01:56.993351Z",
          "iopub.status.busy": "2023-07-12T22:01:56.992775Z",
          "iopub.status.idle": "2023-07-12T22:01:57.001309Z",
          "shell.execute_reply": "2023-07-12T22:01:56.999431Z",
          "shell.execute_reply.started": "2023-07-12T22:01:56.993305Z"
        },
        "papermill": {
          "duration": 0.023635,
          "end_time": "2024-02-21T16:01:18.984122",
          "exception": false,
          "start_time": "2024-02-21T16:01:18.960487",
          "status": "completed"
        },
        "tags": [],
        "id": "ab2388a5"
      },
      "source": [
        "## Summary\n",
        "A very short notebook, but with a lot of content.\n",
        "\n",
        "We have used a vector database to store information. Then move on to retrieve it and use it to create an extended prompt that we've used to call one of the newer large language models available in Hugging Face.\n",
        "\n",
        "The model has returned a response to us taking into account the context that we have passed to it in the prompt.\n",
        "\n",
        "This way of working with language models is very powerful.\n",
        "\n",
        "We can make the model use our information without the need for Fine Tuning. This technique really has some very big advantages over fine tuning.\n",
        "\n",
        "Please don't stop here.\n",
        "\n",
        "* The notebook is prepared to use two more Datasets. Do tests with it.\n",
        "\n",
        "* Find another model on Hugging Face and compare it.\n",
        "\n",
        "* Modify the way to create the prompt."
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 836401,
          "sourceId": 1428159,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 3496946,
          "sourceId": 6104553,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 1977878,
          "sourceId": 7598394,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30527,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 489.921972,
      "end_time": "2024-02-21T16:01:21.828095",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-02-21T15:53:11.906123",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}